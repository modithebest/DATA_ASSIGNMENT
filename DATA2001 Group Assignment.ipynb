{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d809dbaf-7594-4786-b093-07ba2e620e2e",
   "metadata": {},
   "source": [
    "# DATA2001 Group Assignment: Quantifying Resource Availability in Greater Sydney SA2 Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97056c-b6d4-4397-8ce3-acf8a46386ad",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae18de18-bca9-44b9-8ee1-17f3bb7cdfc5",
   "metadata": {},
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a50b942-084d-4dbb-b651-5d08d9a4ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import json\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Database connectivity\n",
    "from sqlalchemy import create_engine, text\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "\n",
    "# Spatial geometry\n",
    "from shapely.geometry import MultiPolygon, Point, Polygon\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import contextily as ctx\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster, FeatureGroupSubGroup\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f502d32-3474-49fd-a7fe-dbcfba62091d",
   "metadata": {},
   "source": [
    "### 1.2 PostgreSQL Connector Setup\n",
    "To streamline database interactions, we define a pgconnect() function that reads connection details from Credentials.json and creates a SQLAlchemy engine pointing to our Postgres instance. This centralizes all authentication and configuration in one place. We then use a query() helper that takes an open connection and a SQL string, executes the statement, and returns the results directly as a pandas DataFrame—making it trivial to pull data from the database into our analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "65083cf7-e1f4-44e5-a4f6-9f36c4cb46ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = \"Credentials.json\"\n",
    "def pgconnect(credential_filepath, db_schema=\"public\"):\n",
    "    \"\"\"\n",
    "    Reads credentials.json, prefers the 'database' key, then 'dbname',\n",
    "    then falls back to the user. Returns (engine, connection).\n",
    "    \"\"\"\n",
    "    with open(credential_filepath, \"r\") as f:\n",
    "        creds = json.load(f)\n",
    "\n",
    "    host   = creds[\"host\"]\n",
    "    port   = creds[\"port\"]\n",
    "    user   = creds[\"user\"]\n",
    "    pw     = creds[\"password\"]\n",
    "    dbname = creds.get(\"database\") or creds.get(\"dbname\") or user\n",
    "\n",
    "    url = f\"postgresql+psycopg2://{user}:{pw}@{host}:{port}/{dbname}\"\n",
    "\n",
    "    try:\n",
    "        engine = create_engine(url, echo=False)\n",
    "        conn   = engine.connect()\n",
    "        print(f\"Connected successfully to '{dbname}'.\")\n",
    "    except Exception as e:\n",
    "        print(\"Unable to connect to the database:\")\n",
    "        print(e)\n",
    "        engine, conn = None, None\n",
    "\n",
    "    return engine, conn\n",
    "\n",
    "def query(engine, sqlcmd, args=None, df=True):\n",
    "    \"\"\"\n",
    "    Convenience wrapper around pandas.read_sql_query or raw execute.\n",
    "    - If df=True: returns a DataFrame via pandas.read_sql_query()\n",
    "    - Else: runs a raw execute() on engine and returns fetched results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if df:\n",
    "            return pd.read_sql_query(sqlcmd, engine, params=args)\n",
    "        else:\n",
    "            result = engine.execute(text(sqlcmd), args).fetchall()\n",
    "            return result[0] if len(result) == 1 else result\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea3202-743f-4141-a3d1-5bbef887b948",
   "metadata": {},
   "source": [
    "### 1.3 Establish Database Connection\n",
    "This line invokes our connector and prepares the session for all subsequent database work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5b17929a-b6b5-41fb-810a-3e468808c17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to connect to the database:\n",
      "(psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  database \"localhost\" does not exist\n",
      "\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "db, conn = pgconnect(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cf11cd-e499-4a91-8d37-fc45fe5d4b36",
   "metadata": {},
   "source": [
    "### 1.4 Verify PostGIS Installation\n",
    "Before running any spatial operations, we perform a quick sanity check by calling the PostGIS_Version() function through our query() helper. A returned version string confirms that the PostGIS extension is installed and that spatial SQL functions are available in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "56c84556-f770-4e64-9722-002ab2bc8607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered: 'NoneType' object has no attribute 'cursor'\n"
     ]
    }
   ],
   "source": [
    "query(conn, \"select PostGIS_Version()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe9051b-9d5c-4668-aa2b-111f6c76afcc",
   "metadata": {},
   "source": [
    "## 2. Data Ingestion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6c02eb-a244-4f84-af23-5c20a4f8ab0d",
   "metadata": {},
   "source": [
    "### 2.1 Import Core CSV Tables\n",
    "Loads business, income, and population data from their respective CSV files. The raw data is initially previewed for structural verification, then deduplicated, and finally loaded into the public.businesses, public.population, and public.income tables in PostgreSQL. This step prepares these foundational datasets for analytical use and linkage with other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74ca0c7-675c-4b5a-ae96-9588c6d37b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "business = pd.read_csv(\"data/Businesses.csv\")\n",
    "print(\"Businesses.csv head:\")\n",
    "print(business.head())\n",
    "\n",
    "income = pd.read_csv(\"data/income.csv\")\n",
    "print(\"\\nincome.csv head:\")\n",
    "print(income.head())\n",
    "\n",
    "population = pd.read_csv(\"data/Population.csv\")\n",
    "print(\"\\nPopulation.csv head:\")\n",
    "print(population.head())\n",
    "\n",
    "print(\"\\nLoading CSVs into PostgreSQL tables...\")\n",
    "for csv_file, table_name in [\n",
    "    (\"data/Businesses.csv\", \"businesses\"),\n",
    "    (\"data/Population.csv\", \"population\"),\n",
    "    (\"data/Income.csv\", \"income\"),\n",
    "]:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.to_sql(\n",
    "        table_name,\n",
    "        conn,\n",
    "        schema = \"public\",\n",
    "        if_exists = \"replace\",\n",
    "        index = False,\n",
    "        method = \"multi\")\n",
    "    print(f\"Loaded {table_name}: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e099bc4e-9f31-4732-a23d-6b98b786ccd3",
   "metadata": {},
   "source": [
    "### 2.2 Create Core Spatial Tables\n",
    "Establishes the initial PostGIS schema for SA2 boundaries and transport stops by creating (or recreating) the public.sa2_regions and public.stops tables. These tables are defined with appropriate geometry columns (MULTIPOLYGON for regions, POINT for stops) and GIST indexes to ensure efficient spatial querying. The sa2_regions table created here serves as a preliminary structure that will be further refined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e93007-9ca5-4182-91d4-832cf055f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sa2_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS public.sa2_regions;\n",
    "CREATE TABLE public.sa2_regions (\n",
    "    sa2_code_2021 TEXT PRIMARY KEY,\n",
    "    sa2_name_2021 TEXT,\n",
    "    geometry      GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\n",
    "CREATE INDEX IF NOT EXISTS sa2_regions_geom_idx\n",
    "    ON public.sa2_regions USING GIST (geometry);\n",
    "\n",
    "DROP TABLE IF EXISTS public.stops;\n",
    "CREATE TABLE public.stops (\n",
    "    stop_id   TEXT PRIMARY KEY,\n",
    "    stop_name TEXT,\n",
    "    geometry  GEOMETRY(POINT,4326)\n",
    ");\n",
    "CREATE INDEX IF NOT EXISTS stops_geom_idx\n",
    "    ON public.stops USING GIST (geometry);\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(text(create_sa2_sql))\n",
    "print(\"\\nCore spatial tables (sa2_regions, stops) structure created/recreated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d0b9c7-2f72-48ba-a02d-3248e77a628b",
   "metadata": {},
   "source": [
    "### 2.3 Load SA2 Boundary Shapefile into PostGIS\n",
    "Loads SA2 geographic boundaries into the public.sa2_regions PostGIS table. Data is read from an SA2 shapefile, processed to standardize column names (including sa2_code, sa2_name, sa4_name_2021, gcc_name_2021), ensure the CRS is EPSG:4326, and remove duplicates. This processed data then replaces any prior version of the public.sa2_regions table. Finally, a primary key on sa2_code and a GIST spatial index on the geometry are conditionally created to ensure data integrity and optimize spatial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f66bf-332f-4f87-9c20-6754a78d19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa2 = (\n",
    "    gpd.read_file(\"data/SA2_2021_AUST_SHP_GDA2020/SA2_2021_AUST_GDA2020.shp\")[\n",
    "        [\"SA2_CODE21\", \"SA2_NAME21\", \"SA4_NAME21\", \"GCC_NAME21\", \"geometry\"]\n",
    "    ]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"SA2_CODE21\": \"sa2_code\",\n",
    "            \"SA2_NAME21\": \"sa2_name\",\n",
    "            \"SA4_NAME21\": \"sa4_name_2021\",\n",
    "            \"GCC_NAME21\": \"gcc_name_2021\",\n",
    "        }\n",
    "    )\n",
    "    .to_crs(4326)\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "sa2.to_postgis(\n",
    "    \"sa2_regions\", conn,\n",
    "    schema=\"public\",\n",
    "    if_exists=\"replace\",\n",
    "    index=False,\n",
    "    dtype={\"geometry\": Geometry(\"MULTIPOLYGON\", 4326)}\n",
    ")\n",
    "print(f\"\\nInserted {len(sa2):,} SA2 rows, replacing sa2_regions table.\")\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DO $$\n",
    "BEGIN\n",
    "  IF NOT EXISTS (\n",
    "      SELECT 1 FROM pg_constraint\n",
    "      WHERE conrelid = 'public.sa2_regions'::regclass\n",
    "        AND conname = 'sa2_regions_pkey'\n",
    "  ) THEN\n",
    "      ALTER TABLE public.sa2_regions\n",
    "        ADD CONSTRAINT sa2_regions_pkey PRIMARY KEY (sa2_code);\n",
    "  END IF;\n",
    "\n",
    "  IF NOT EXISTS (\n",
    "      SELECT 1 FROM pg_indexes\n",
    "      WHERE schemaname = 'public'\n",
    "        AND tablename  = 'sa2_regions'\n",
    "        AND indexname  = 'sa2_regions_geom_idx'\n",
    "  ) THEN\n",
    "      CREATE INDEX sa2_regions_geom_idx\n",
    "        ON public.sa2_regions USING GIST (geometry);\n",
    "  END IF;\n",
    "END $$;\n",
    "\"\"\"))\n",
    "print(\"Primary key and GIST index on sa2_regions verified/created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e39d46c-25d5-41ab-b95f-03112ddc3195",
   "metadata": {},
   "source": [
    "### 2.4 Insert Transport Stops from GTFS\n",
    "Populates the public.stops table with public transport stop locations. Data sourced from Stops.txt (typically part of a GTFS feed) is deduplicated and transformed into a spatial format by creating POINT geometries from latitude/longitude coordinates (CRS EPSG:4326). These stop locations are then appended to the public.stops table, leveraging the schema and GIST index established earlier, to provide a spatial layer for transit infrastructure analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb2dc08-ce91-4bdf-b907-584b3550a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = pd.read_csv(\"data/Stops.txt\")\n",
    "stops.drop_duplicates(inplace=True)\n",
    "\n",
    "stops_gdf = gpd.GeoDataFrame(\n",
    "    stops[[\"stop_id\",\"stop_name\"]],\n",
    "    geometry=gpd.points_from_xy(stops.stop_lon, stops.stop_lat),\n",
    "    crs=4326\n",
    ")\n",
    "\n",
    "stops_gdf.to_postgis(\"stops\", conn,\n",
    "                     schema=\"public\",\n",
    "                     if_exists=\"append\",\n",
    "                     index=False,\n",
    "                     dtype={\"geometry\": Geometry(\"POINT\",4326)})\n",
    "\n",
    "print(f\"\\nInserted {len(stops_gdf):,} stops into public.stops table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c384c-855e-488f-b064-ae6c3a0ff9bc",
   "metadata": {},
   "source": [
    "### 2.5 Load School Catchment Polygons\n",
    "Integrates school catchment boundaries into the public.schools PostGIS table. Data from separate shapefiles for primary, secondary, and future catchments is read, standardized (CRS to EPSG:4326, columns renamed, 'sector' attribute added), consolidated, and deduplicated. This comprehensive catchment data is then loaded into a newly created public.schools table, structured with a surrogate primary key (gid), MULTIPOLYGON geometry, and a GIST spatial index to facilitate analysis of educational access areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfced522-c6c4-48f1-ba95-c70b4dac4353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_catch(path):\n",
    "    gdf = gpd.read_file(path).to_crs(4326)\n",
    "    gdf = gdf.rename(columns={\n",
    "        \"USE_ID\": \"school_id\",\n",
    "        \"CATCH_TYPE\": \"stage\"\n",
    "    })\n",
    "    gdf[\"sector\"] = \"Government\"\n",
    "    return gdf[[\"school_id\", \"sector\", \"stage\", \"geometry\"]]\n",
    "\n",
    "gdf_primary   = read_catch(\"data/catchments/catchments_primary.shp\")\n",
    "gdf_secondary = read_catch(\"data/catchments/catchments_secondary.shp\")\n",
    "gdf_future    = read_catch(\"data/catchments/catchments_future.shp\")\n",
    "\n",
    "schools = pd.concat([gdf_primary, gdf_secondary, gdf_future], ignore_index=True)\n",
    "schools.drop_duplicates(inplace=True)\n",
    "print(f\"\\nTotal unique school polygons prepared: {len(schools):,}\")\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS public.schools;\n",
    "CREATE TABLE public.schools (\n",
    "    gid       SERIAL PRIMARY KEY,\n",
    "    school_id TEXT,\n",
    "    sector    TEXT,\n",
    "    stage     TEXT,\n",
    "    geometry  GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\n",
    "CREATE INDEX schools_geom_idx\n",
    "  ON public.schools USING GIST (geometry);\n",
    "\"\"\"))\n",
    "print(\"Recreated public.schools table with GIST index.\")\n",
    "\n",
    "schools.to_postgis(\"schools\", conn, schema=\"public\",\n",
    "                   if_exists=\"append\", index=False,\n",
    "                   dtype={\"geometry\": Geometry(\"MULTIPOLYGON\",4326)})\n",
    "print(\"School catchments loaded into public.schools table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7738ed6a-64c2-48eb-9e1c-55c1294131b5",
   "metadata": {},
   "source": [
    "### 2.6 Build Indexes on SA2 Key Columns\n",
    "Optimizes data retrieval performance by creating B-tree indexes on the SA2 key columns (e.g., sa2_code or sa2_code21) within the public.businesses, public.population, and public.income tables. These indexes are created if they don't already exist and significantly accelerate join operations between these attribute tables and the public.sa2_regions spatial table, enabling efficient linkage of demographic and economic data to geographic areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6fa563-7d2d-4245-b47c-1a56653d651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "    CREATE INDEX IF NOT EXISTS businesses_sa2_idx\n",
    "      ON public.businesses (sa2_code);\n",
    "    CREATE INDEX IF NOT EXISTS population_sa2_idx\n",
    "      ON public.population (sa2_code);\n",
    "    CREATE INDEX IF NOT EXISTS income_sa2_idx\n",
    "      ON public.income (sa2_code21);\n",
    "\"\"\"))\n",
    "print(\"\\nIndexes created on sa2_code columns for businesses, population, and income tables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b705b5-a0df-484d-9869-fc4ccc375490",
   "metadata": {},
   "source": [
    "### 2.7 Validate Table Loads\n",
    "Confirms the completeness of the data ingestion process by querying and displaying the row counts for all key tables created or populated in the public schema: sa2_regions, stops, schools, businesses, population, and income. This serves as a fundamental validation step to ensure that each dataset has been loaded as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b4bc8b-353e-436d-84f8-db45259448f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRow counts in public tables:\")\n",
    "row_counts_df = pd.read_sql(\"\"\"\n",
    "SELECT 'sa2_regions' AS table_name, COUNT(*) AS rows FROM public.sa2_regions\n",
    "UNION ALL\n",
    "SELECT 'stops',        COUNT(*) FROM public.stops\n",
    "UNION ALL\n",
    "SELECT 'schools',      COUNT(*) FROM public.schools\n",
    "UNION ALL\n",
    "SELECT 'businesses',   COUNT(*) FROM public.businesses\n",
    "UNION ALL\n",
    "SELECT 'population',   COUNT(*) FROM public.population\n",
    "UNION ALL\n",
    "SELECT 'income',       COUNT(*) FROM public.income;\n",
    "\"\"\", conn)\n",
    "print(row_counts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fc76d9-852f-474c-b016-cf79d3e487aa",
   "metadata": {},
   "source": [
    "### 2.8 Confirm Spatial Metadata\n",
    "Verifies the consistency of spatial data across the database by querying the geometry_columns system catalog. This lists all tables in the public schema that contain geometry columns, along with their Spatial Reference ID (SRID). This check ensures that all spatial data correctly uses the designated coordinate system (e.g., EPSG:4326), which is crucial for accurate spatial operations and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a377a-2c0a-4d15-ae33-484c2ac08f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSRID of geometry columns in public schema:\")\n",
    "srid_df = pd.read_sql(\"\"\"\n",
    "SELECT f_table_schema AS schema_name, f_table_name AS table_name, f_geometry_column AS geometry_column, srid\n",
    "FROM   geometry_columns\n",
    "WHERE  f_table_schema = 'public';\n",
    "\"\"\", conn)\n",
    "print(srid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ee8e9-a03b-43d6-bfd7-eb585f680f3d",
   "metadata": {},
   "source": [
    "### 2.9 Connection Diagnostics\n",
    "Provides diagnostic information about the current database connection by displaying the SQLAlchemy engine URL, the DSN (Data Source Name) parameters of the connection, and the name of the currently active database (queried directly). This output helps in verifying that the script is connected to the intended database environment and can aid in troubleshooting any connection-related issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cebf74-7dc3-4a54-bd20-ee5a149a1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'engine' in locals() or 'engine' in globals():\n",
    "    print(\"\\nengine    →\", engine.url)\n",
    "else:\n",
    "    print(\"\\nEngine object 'engine' not found for diagnostics.\")\n",
    "\n",
    "if 'conn' in locals() and conn and conn.connection:\n",
    "    try:\n",
    "        dsn_params = conn.connection.get_dsn_parameters()\n",
    "        print(\"conn DSN  →\", dsn_params)\n",
    "        current_db_df = pd.read_sql(text(\"SELECT current_database()\"), conn) # conn instead of db\n",
    "        print(\"current_db→\", current_db_df.iloc[0,0])\n",
    "    except AttributeError:\n",
    "        print(\"Could not retrieve DSN parameters or current_database using this connection object.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during connection diagnostics: {e}\")\n",
    "else:\n",
    "    print(\"Connection object 'conn' not available or not active for diagnostics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a5619c-6a2e-4eed-8493-68b80a6f0434",
   "metadata": {},
   "source": [
    "### 2.10 WEB API WILSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a3e706-8e09-479a-9876-83c1b7ef2cdb",
   "metadata": {},
   "source": [
    "this code queries the NSW SIX Maps POI API to retrieve POIs within specified bounding box defined by minimum and maximum longitude and latitude coordinates. It sends an HTTP GET request with spatial parameters, parsed the returned JSON response, and then extracts relevant POI attributes and coordinates. The result is returned as a Pandas DataFrame containing POI name, type, group, labels, and geographic location, along with the raw JSON response for optional inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e06db-29b2-409a-b8d8-6fe8a0549d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_pois_from_api(minx, miny, maxx, maxy):\n",
    "    \n",
    "    url = \"https://maps.six.nsw.gov.au/arcgis/rest/services/public/NSW_POI/MapServer/0/query\"\n",
    "    \n",
    "    params = {\n",
    "        \"where\": \"1=1\",\n",
    "        \"geometry\": f\"{minx},{miny},{maxx},{maxy}\",\n",
    "        \"geometryType\": \"esriGeometryEnvelope\",\n",
    "        \"spatialRel\": \"esriSpatialRelIntersects\",\n",
    "        \"outFields\": \"*\",\n",
    "        \"returnGeometry\": \"true\",\n",
    "        \"f\": \"json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error fetching data:\", response.status_code)\n",
    "        return pd.DataFrame(), {}\n",
    "    \n",
    "    result = response.json()\n",
    "\n",
    "    if \"features\" not in result:\n",
    "        return pd.DataFrame(), result\n",
    "    \n",
    "    pois = []\n",
    "    \n",
    "    for feature in result[\"features\"]:\n",
    "        attr = feature[\"attributes\"]\n",
    "        geom = feature.get(\"geometry\", {})\n",
    "        \n",
    "        pois.append({\n",
    "            \"POIName\": attr.get(\"poiname\", None),\n",
    "            \"POIType\": attr.get(\"poitype\", None),\n",
    "            \"POIGroup\": attr.get(\"poigroup\", None),\n",
    "            \"POILabel\": attr.get(\"poilabel\", None),\n",
    "            \"POIAltLabel\": attr.get(\"poialtlabel\", None),\n",
    "            \"POILabelType\": attr.get(\"poilabeltype\", None),\n",
    "            \"Longitude\": geom.get(\"x\", None),\n",
    "            \"Latitude\": geom.get(\"y\", None)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(pois), result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe3bc3f-c278-4682-8a54-e30f83d29fcf",
   "metadata": {},
   "source": [
    "This code retreives POIs for SA2 regions within our selected SA4 areas (Sydney - Blacktown, Parramatta, and Ryde) by querying their bounding boxes from a PostgreSQL. It parses the bounding box coordinates, calls the provided API to fetch POIs for each region, appends SA2 metadata to the results, and pauses between requests for 1s to not hit API limits. The collected POIs are then combined and stored in the nsw_poi table within the database, replacing any existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d444bb-22c3-4356-aa31-cef9dfce1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sqlalchemy import text, String, Integer, Float, DateTime\n",
    "\n",
    "selected_sa4 = [\"Sydney - Blacktown\", \"Sydney - Parramatta\", \"Sydney - Ryde\"]\n",
    "selected_sa4_str = \", \".join(f\"'{sa4}'\" for sa4 in selected_sa4)\n",
    "\n",
    "sa2_df = pd.read_sql(f\"\"\"\n",
    "SELECT sa2_code, sa2_name, sa4_name_2021, ST_Extent(geometry) AS bbox\n",
    "FROM public.sa2_regions\n",
    "WHERE sa4_name_2021 IN ({selected_sa4_str})\n",
    "GROUP BY sa2_code, sa2_name, sa4_name_2021\n",
    "\"\"\", conn)\n",
    "\n",
    "def bbox_parse(bbox_str):\n",
    "    bbox_str = bbox_str.replace(\"BOX(\", \"\").replace(\")\", \"\")\n",
    "    min_point, max_point = bbox_str.split(\",\")\n",
    "    minx, miny = map(float, min_point.strip().split(\" \"))\n",
    "    maxx, maxy = map(float, max_point.strip().split(\" \"))\n",
    "    return minx, miny, maxx, maxy\n",
    "\n",
    "sa2_df[[\"min_lon\", \"min_lat\", \"max_lon\", \"max_lat\"]] = sa2_df[\"bbox\"].apply(lambda x: pd.Series(bbox_parse(x)))\n",
    "\n",
    "results = []\n",
    "\n",
    "for index, row in sa2_df.iterrows():\n",
    "    sa2_code = row[\"sa2_code\"]\n",
    "    sa2_name = row[\"sa2_name\"]\n",
    "    min_lon = row[\"min_lon\"]\n",
    "    min_lat = row[\"min_lat\"]\n",
    "    max_lon = row[\"max_lon\"]\n",
    "    max_lat = row[\"max_lat\"]\n",
    "\n",
    "    print(f\"Fetching POIs for SA2: {sa2_name}\")\n",
    "\n",
    "    poi_df, result_p = get_pois_from_api(min_lon, min_lat, max_lon, max_lat)\n",
    "    # print(result_p)\n",
    "\n",
    "    if poi_df.empty:\n",
    "        continue\n",
    "\n",
    "    poi_df[\"SA2_CODE\"] = sa2_code\n",
    "    poi_df[\"SA2_NAME\"] = sa2_name\n",
    "    results.append(poi_df)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"Finished fetching POIs.\")\n",
    "\n",
    "if results:\n",
    "    final_poi_df = pd.concat(results, ignore_index=True)\n",
    "    print(f\"Total POIs fetched: {len(final_poi_df)}\")\n",
    "    display(final_poi_df.head())\n",
    "    \n",
    "\n",
    "    final_poi_df.to_sql(\"nsw_poi\", db, if_exists=\"replace\", index=False, dtype={\n",
    "        \"POIName\": String(),\n",
    "        \"POIType\": String(),\n",
    "        \"POIGroup\": Integer(),\n",
    "        \"POILabel\": String(),\n",
    "        \"POIAltLabel\": String(),\n",
    "        \"POILabelType\": String(),\n",
    "        \"Longitude\": Float(),\n",
    "        \"Latitude\": Float(),\n",
    "        \"SA2_CODE\": String(),\n",
    "        \"SA2_NAME\": String(),\n",
    "        \"timestamp\": String()   \n",
    "    })\n",
    "\n",
    "    print(\"POIs successfully inserted into table 'nsw_poi'.\")\n",
    "else:\n",
    "    print(\"No POIs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7380f112-770d-4027-b7d5-89f5d8c7a0e4",
   "metadata": {},
   "source": [
    "## 3. Score Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe964355-6213-40e5-a70f-75f51c1083b7",
   "metadata": {},
   "source": [
    "### 3.1 Business z-Score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3553e42c-98c8-49d7-b6a1-058bd85cdfc2",
   "metadata": {},
   "source": [
    "We focus on industries that directly provide everyday goods, services, and amenities to local residents. To that end, we exclude:\n",
    "\n",
    "- **Heavy-industry & utilities**  \n",
    "  _(Mining, Manufacturing, Agriculture, Electricity/Gas/Water/Waste, Construction)_  \n",
    "  These sectors typically locate outside dense population centers and don’t reflect the local availability of shops, clinics, or leisure services.\n",
    "\n",
    "- **Public Administration & Safety**  \n",
    "  Although essential, these are government-run functions rather than private-sector businesses, and so are better handled by dedicated public-sector layers.\n",
    "\n",
    "- **Administrative & Support Services**  \n",
    "  Roles like cleaning, security, or back-office operations don’t signal consumer-facing amenities; they rarely indicate local resource richness from a resident’s perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d454c82d-97f5-4af1-b24e-348f3b2ceea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = text(\"\"\"\n",
    "DROP TABLE IF EXISTS public.sa2_summary;\n",
    "\n",
    "CREATE TABLE public.sa2_summary AS\n",
    "SELECT\n",
    "  sr.sa2_code,\n",
    "  sr.sa2_name,\n",
    "  SUM(b.total_businesses)\n",
    "    / (pop.total_people   / 1000.0) AS business_count\n",
    "FROM businesses b\n",
    "  JOIN sa2_regions    sr  USING (sa2_name)\n",
    "  JOIN population pop USING (sa2_name)\n",
    "WHERE sr.sa4_name_2021 IN (\n",
    "    'Sydney - Blacktown',\n",
    "    'Sydney - Parramatta',\n",
    "    'Sydney - Ryde'\n",
    "  )\n",
    "  AND b.industry_name IN (\n",
    "    'Health Care and Social Assistance',\n",
    "    'Education and Training',\n",
    "    'Retail Trade',\n",
    "    'Accommodation and Food Services',\n",
    "    'Transport, Postal and Warehousing',\n",
    "    'Financial and Insurance Services',\n",
    "    'Professional, Scientific and Technical Services',\n",
    "    'Arts and Recreation Services',\n",
    "    'Rental, Hiring and Real Estate Services'\n",
    "  )\n",
    "  AND total_people >= 100\n",
    "GROUP BY\n",
    "  sr.sa2_code,\n",
    "  sr.sa2_name,\n",
    "  pop.total_people\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(sql)\n",
    "\n",
    "\n",
    "summary_df = query(conn, \"SELECT * FROM public.sa2_summary;\")\n",
    "print(summary_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ef19a-d650-4155-bfaa-5d1d55f4f281",
   "metadata": {},
   "source": [
    "### 3.2 Transport Stops z-Score  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f560a022-911d-432a-8a8b-e23e6ec3b31b",
   "metadata": {},
   "source": [
    "We quantify local transit access by counting every bus, train and tram stop located within each SA2 boundary. A higher `stops_count` not only signals more frequent service options, but also reflects greater ease of movement—letting residents run errands, commute or access leisure activities without relying on a car. By mapping stop density in this way, we capture how well-connected each neighbourhood is to the wider city network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b4fa7a-5236-4b85-a97c-e8f5bc6e2bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = text(\"\"\"\n",
    "-- 1) Add the new column if it doesn't already exist\n",
    "ALTER TABLE public.sa2_summary\n",
    "ADD COLUMN IF NOT EXISTS stops_count INTEGER;\n",
    "\n",
    "-- 2) Update that column by counting stops per SA2\n",
    "UPDATE public.sa2_summary AS summ\n",
    "SET stops_count = sub.stops_count\n",
    "FROM (\n",
    "  SELECT\n",
    "    sr.sa2_name,\n",
    "    COUNT(*) AS stops_count\n",
    "  FROM sa2_regions AS sr\n",
    "  JOIN stops AS s\n",
    "    ON ST_Contains(sr.geometry, s.geometry)\n",
    "  WHERE\n",
    "    sr.sa4_name_2021 IN (\n",
    "      'Sydney - Blacktown',\n",
    "      'Sydney - Parramatta',\n",
    "      'Sydney - Ryde'\n",
    "    )\n",
    "  GROUP BY\n",
    "    sr.sa2_name\n",
    ") AS sub\n",
    "WHERE summ.sa2_name = sub.sa2_name;\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(sql)\n",
    "\n",
    "summary_df = query(\n",
    "    conn,\n",
    "    \"SELECT * FROM public.sa2_summary;\"\n",
    ")\n",
    "print(summary_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f08dc-66f7-4fc5-9e9b-bd2abcef14b8",
   "metadata": {},
   "source": [
    "### 3.3 Schools z-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae06bd7d-2727-4b21-95bf-ce470afce095",
   "metadata": {},
   "source": [
    "We gauge local education availability by counting the number of unique school-catchment polygons that overlap each SA2, then normalizing this as **catchments per 1 000 young residents**. Higher values indicate more schooling options relative to the size of the youth population.\n",
    "\n",
    "- We derive **young_pop** by summing age bands 0–4, 5–9, 10–14 and 15–19 for each SA2.  \n",
    "- We exclude any SA2 with **young_pop < 100** to avoid unstable per-capita rates in areas with very few children.  \n",
    "- The raw catchment count is divided by **(young_pop / 1 000)**, ensuring that areas with smaller youth populations don’t produce disproportionately large metrics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672cd39-d59f-4210-923e-c95597fb7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = text(\"\"\"\n",
    "-- 1) Add the new column if it doesn't already exist\n",
    "ALTER TABLE public.sa2_summary\n",
    "ADD COLUMN IF NOT EXISTS catchments_count DOUBLE PRECISION;\n",
    "\n",
    "-- 2) Update that column by computing catchments per 1 000 young people\n",
    "WITH pop_young AS (\n",
    "  SELECT\n",
    "    sa2_name,\n",
    "    (\n",
    "      \"0-4_people\"\n",
    "    + \"5-9_people\"\n",
    "    + \"10-14_people\"\n",
    "    + \"15-19_people\"\n",
    "    ) AS young_pop\n",
    "  FROM population\n",
    ")\n",
    "UPDATE public.sa2_summary AS summ\n",
    "SET catchments_count = sub.catchments_count\n",
    "FROM (\n",
    "  SELECT\n",
    "    sr.sa2_name,\n",
    "    COUNT(*)::float\n",
    "      / (pyoung.young_pop / 1000.0) AS catchments_count\n",
    "  FROM schools      AS s\n",
    "  JOIN sa2_regions AS sr\n",
    "    ON  ST_Intersects(sr.geometry, s.geometry)\n",
    "    AND NOT ST_Touches(   sr.geometry, s.geometry)\n",
    "  JOIN pop_young   AS pyoung\n",
    "    ON pyoung.sa2_name = sr.sa2_name\n",
    "  WHERE\n",
    "    sr.sa4_name_2021 IN (\n",
    "      'Sydney - Blacktown',\n",
    "      'Sydney - Parramatta',\n",
    "      'Sydney - Ryde'\n",
    "    )\n",
    "    AND pyoung.young_pop >= 100\n",
    "  GROUP BY\n",
    "    sr.sa2_name,\n",
    "    pyoung.young_pop\n",
    ") AS sub\n",
    "WHERE summ.sa2_name = sub.sa2_name;\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(sql)\n",
    "\n",
    "summary_df = query(\n",
    "    conn,\n",
    "    \"SELECT * FROM public.sa2_summary;\"\n",
    ")\n",
    "print(summary_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ebb085-449d-45ef-bb3c-b175173b82fd",
   "metadata": {},
   "source": [
    "### 3.4 Points of Interest z-Score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e2fd2-6985-4ce0-af86-ae598fc95049",
   "metadata": {},
   "source": [
    "We measure local amenity richness by counting only those POIs that represent everyday, community-facing services within each SA2. All other facility types are excluded to ensure the metric reflects true neighborhood resources:\n",
    "\n",
    "- **Industrial & Utility Sites**  \n",
    "  (e.g., Filtration Plant, Sewage Works, Pumping Station)  \n",
    "  These support core infrastructure but are not public amenities.\n",
    "\n",
    "- **Large-Scale Commercial & Tourism Facilities**  \n",
    "  (e.g., Tourist Park, Silo – Commercial, Quarry – Open Cut)  \n",
    "  Typically located outside residential centers and not part of everyday life.\n",
    "\n",
    "- **Broad or Redundant Place Categories**  \n",
    "  (e.g., City, Suburb, Locality)  \n",
    "  Geographic labels rather than specific service points.\n",
    "\n",
    "- **Niche or Infrequent-Use Sites**  \n",
    "  (e.g., Motor Racing Track, Helipad, Gaol)  \n",
    "  Specialized venues with limited regular community access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55346349-b426-4cc6-b244-9b38dcd41730",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = text(\"\"\"\n",
    "-- 1) Add the new column if it doesn't already exist\n",
    "ALTER TABLE public.sa2_summary\n",
    "ADD COLUMN IF NOT EXISTS poi_count INTEGER;\n",
    "\n",
    "-- 2) Update that column by counting POIs per SA2\n",
    "UPDATE public.sa2_summary AS summ\n",
    "SET poi_count = sub.poi_count\n",
    "FROM (\n",
    "  SELECT\n",
    "    sr.sa2_name,\n",
    "    COUNT(*) AS poi_count\n",
    "  FROM nsw_poi AS n\n",
    "  JOIN sa2_regions AS sr\n",
    "    ON sr.sa2_name = n.\"SA2_NAME\"\n",
    "  WHERE\n",
    "    sr.sa4_name_2021 IN (\n",
    "      'Sydney - Blacktown',\n",
    "      'Sydney - Parramatta',\n",
    "      'Sydney - Ryde'\n",
    "    )\n",
    "    AND n.\"POIType\" IN (\n",
    "      'Library',\n",
    "      'Park',\n",
    "      'Community Facility',\n",
    "      'Child Care Centre',\n",
    "      'Primary School',\n",
    "      'High School',\n",
    "      'General Hospital',\n",
    "      'Community Medical Centre',\n",
    "      'Transport Interchange',\n",
    "      'Post Office',\n",
    "      'Sports Centre / Sports Field',\n",
    "      'Art Gallery / Museum'\n",
    "    )\n",
    "  GROUP BY\n",
    "    sr.sa2_name\n",
    ") AS sub\n",
    "WHERE summ.sa2_name = sub.sa2_name;\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(sql)\n",
    "\n",
    "summary_df = query(\n",
    "    conn,\n",
    "    \"SELECT * FROM public.sa2_summary;\"\n",
    ")\n",
    "print(summary_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b26b62-c9eb-43e1-82f7-8f0577409662",
   "metadata": {},
   "source": [
    "### 3.5 Composite Score & Sigmoid Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b9f8c5-5136-42c5-9e04-7cc3ab094e96",
   "metadata": {},
   "source": [
    "We standardize and merge our four resource metrics—`business_count`, `stops_count`, `catchments_count`, and `poi_count`—into a single, comparable score:\n",
    "\n",
    "- **Z-Score Standardization**  \n",
    "  Convert each raw count into a z-score by subtracting the overall mean and dividing by the population standard deviation. This puts all metrics on the same scale, so large-count categories don’t dominate the index.\n",
    "\n",
    "- **Summation of Standardized Metrics**  \n",
    "  Add the four z‐scores together to create `z_total`. Positive totals indicate above-average resource levels across all categories; negative totals indicate below-average.\n",
    "\n",
    "- **Sigmoid Transformation**  \n",
    "  Apply a logistic (sigmoid) function to `z_total` to squash the result into the (0, 1) range. A final `well_resourced_score` near 1 means very well-resourced; near 0 means poorly-resourced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85393dd6-f0e2-4506-a76e-87361a3bc97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = text(\"\"\"\n",
    "ALTER TABLE public.sa2_summary\n",
    "  ADD COLUMN IF NOT EXISTS z_business          DOUBLE PRECISION,\n",
    "  ADD COLUMN IF NOT EXISTS z_stops             DOUBLE PRECISION,\n",
    "  ADD COLUMN IF NOT EXISTS z_schools           DOUBLE PRECISION,\n",
    "  ADD COLUMN IF NOT EXISTS z_poi               DOUBLE PRECISION,\n",
    "  ADD COLUMN IF NOT EXISTS z_total             DOUBLE PRECISION,\n",
    "  ADD COLUMN IF NOT EXISTS well_resourced_score DOUBLE PRECISION;\n",
    "\n",
    "WITH stats AS (\n",
    "  SELECT\n",
    "    AVG(business_count)      AS mean_bc,\n",
    "    STDDEV_POP(business_count) AS sd_bc,\n",
    "    AVG(stops_count)         AS mean_sc,\n",
    "    STDDEV_POP(stops_count)    AS sd_sc,\n",
    "    AVG(catchments_count)    AS mean_cc,\n",
    "    STDDEV_POP(catchments_count) AS sd_cc,\n",
    "    AVG(poi_count)           AS mean_pc,\n",
    "    STDDEV_POP(poi_count)      AS sd_pc\n",
    "  FROM public.sa2_summary\n",
    ")\n",
    "UPDATE public.sa2_summary\n",
    "SET\n",
    "  z_business = (COALESCE(business_count, 0) - stats.mean_bc) / NULLIF(stats.sd_bc,0),\n",
    "  z_stops    = (COALESCE(stops_count, 0)    - stats.mean_sc) / NULLIF(stats.sd_sc,0),\n",
    "  z_schools  = (COALESCE(catchments_count, 0) - stats.mean_cc) / NULLIF(stats.sd_cc,0),\n",
    "  z_poi      = (COALESCE(poi_count, 0)      - stats.mean_pc) / NULLIF(stats.sd_pc,0),\n",
    "  z_total    = (\n",
    "      (COALESCE(business_count, 0)   - stats.mean_bc) / NULLIF(stats.sd_bc,0)\n",
    "    + (COALESCE(stops_count, 0)      - stats.mean_sc) / NULLIF(stats.sd_sc,0)\n",
    "    + (COALESCE(catchments_count, 0) - stats.mean_cc) / NULLIF(stats.sd_cc,0)\n",
    "    + (COALESCE(poi_count, 0)        - stats.mean_pc) / NULLIF(stats.sd_pc,0)\n",
    "  ),\n",
    "  well_resourced_score = 1.0 / (1.0 + EXP(-(\n",
    "      (business_count   - stats.mean_bc) / NULLIF(stats.sd_bc,0)\n",
    "    + (stops_count      - stats.mean_sc) / NULLIF(stats.sd_sc,0)\n",
    "    + (catchments_count - stats.mean_cc) / NULLIF(stats.sd_cc,0)\n",
    "    + (poi_count        - stats.mean_pc) / NULLIF(stats.sd_pc,0)\n",
    "  )))\n",
    "FROM stats;\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(sql)\n",
    "\n",
    "summary_df = query(\n",
    "    conn,\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "      sa2_code, \n",
    "      sa2_name, \n",
    "      z_business, \n",
    "      z_stops, \n",
    "      z_schools, \n",
    "      z_poi, \n",
    "      z_total, \n",
    "      well_resourced_score\n",
    "    FROM public.sa2_summary\n",
    "    \"\"\"\n",
    ")\n",
    "print(summary_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992b80ee-7108-40af-989a-419d90aa5c79",
   "metadata": {},
   "source": [
    "## 4. Score Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a9dc96-ea02-41c3-9994-9af175e878c9",
   "metadata": {},
   "source": [
    "### 4.1 Component Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64246419-8a1f-4650-b2a0-3b6ebcce9d7a",
   "metadata": {},
   "source": [
    "Visualizes the contribution of individual components (businesses, transit stops, schools, points of interest) to the overall \"well-resourced score\" for each SA2 region. This analysis uses boxplots to show the distribution of z-scores for each component, highlighting the variability and typical impact of each factor on the final scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d1ed6b-f3bc-4ddb-8724-9b618b5f3fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "components_df = pd.read_sql(text(\"\"\"\n",
    "    SELECT\n",
    "        sa2_name,\n",
    "        z_business,\n",
    "        z_stops,\n",
    "        z_schools,\n",
    "        z_poi,\n",
    "        well_resourced_score\n",
    "    FROM public.sa2_summary\n",
    "    ORDER BY well_resourced_score DESC\n",
    "\"\"\"), conn)\n",
    "\n",
    "melted_df = pd.melt(components_df,\n",
    "                    id_vars=['sa2_name', 'well_resourced_score'],\n",
    "                    value_vars=['z_business', 'z_stops', 'z_schools', 'z_poi'],\n",
    "                    var_name='Component',\n",
    "                    value_name='Z-Score')\n",
    "\n",
    "component_names = {\n",
    "    'z_business': 'Businesses',\n",
    "    'z_stops': 'Transit Stops',\n",
    "    'z_schools': 'Schools',\n",
    "    'z_poi': 'Points of Interest'\n",
    "}\n",
    "melted_df['Component'] = melted_df['Component'].map(component_names)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=melted_df, x='Component', y='Z-Score', palette='Set2', hue='Component')\n",
    "plt.title('Distribution of Z-Scores by Component', fontsize=14)\n",
    "plt.xlabel('Component', fontsize=12)\n",
    "plt.ylabel('Z-Score', fontsize=12)\n",
    "\n",
    "plt.axhline(0, color='gray', linestyle='--', alpha=0.7, label='Zero Reference')\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "for i, comp in enumerate(component_names.values()):\n",
    "    subset = melted_df[melted_df['Component'] == comp]['Z-Score']\n",
    "    median = subset.median()\n",
    "    plt.annotate(f'Median: {median:.2f}',\n",
    "                 xy=(i, subset.min() - 0.2),\n",
    "                 ha='center',\n",
    "                 fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e71101-d38e-4eb8-a4a0-c4afaf7b75ec",
   "metadata": {},
   "source": [
    "### 4.2 Distribution Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be13dfca-0f24-46c5-93e3-de7c23c5e57f",
   "metadata": {},
   "source": [
    "#### 4.2.1 Histogram of composite scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d807c4f-fe14-4bcc-8c89-23ef4131b341",
   "metadata": {},
   "source": [
    "Displays the overall distribution of the composite \"well-resourced scores\" across all analyzed SA2 regions. A histogram is generated to show the frequency of scores within different ranges, providing insight into whether scores are concentrated or spread out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c611e85-a265-477e-ba6f-3e78ce01062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.read_sql(text(\"\"\"\n",
    "    SELECT\n",
    "        public.sa2_summary.sa2_name,\n",
    "        well_resourced_score,\n",
    "        sa4_name_2021\n",
    "    FROM public.sa2_summary\n",
    "    JOIN public.sa2_regions USING (sa2_code)\n",
    "\"\"\"), conn)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(scores_df['well_resourced_score'], bins=15, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Well-Resourced Scores')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Number of SA2 Regions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab673d8-7732-4897-8fdf-0e500badfb32",
   "metadata": {},
   "source": [
    "### 4.2.2 Overall stats (mean, median, std, IQR)\n",
    "This code generates the overall statistics includes mean, median, spread which is standard deviation and interquartile range. It is done bymerging summary data with SA4 region names, compute the stats, then it groups the data by SA4 region and calculates the same metrics for each individual SA4. The results are merged into a single DataFrame and displayed as a table, allowing for a clear cross-region comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e7e732c0-bd23-4def-adb8-ec2bdf4e74f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered: 'NoneType' object has no attribute 'cursor'\n",
      "Error encountered: 'NoneType' object has no attribute 'cursor'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'merge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m summary_df \u001b[38;5;241m=\u001b[39m query(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM public.sa2_summary;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m sa2_regions_df \u001b[38;5;241m=\u001b[39m query(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT sa2_code, sa2_name, sa4_name_2021 FROM public.sa2_regions;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m summary_df \u001b[38;5;241m=\u001b[39m summary_df\u001b[38;5;241m.\u001b[39mmerge(sa2_regions_df, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msa2_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msa2_name\u001b[39m\u001b[38;5;124m\"\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m q1 \u001b[38;5;241m=\u001b[39m summary_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwell_resourced_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.25\u001b[39m)\n\u001b[1;32m      6\u001b[0m q3 \u001b[38;5;241m=\u001b[39m summary_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwell_resourced_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.75\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'merge'"
     ]
    }
   ],
   "source": [
    "summary_df = query(conn, \"SELECT * FROM public.sa2_summary;\")\n",
    "sa2_regions_df = query(conn, \"SELECT sa2_code, sa2_name, sa4_name_2021 FROM public.sa2_regions;\")\n",
    "summary_df = summary_df.merge(sa2_regions_df, on=[\"sa2_code\", \"sa2_name\"], how=\"left\")\n",
    "\n",
    "q1 = summary_df[\"well_resourced_score\"].quantile(0.25)\n",
    "q3 = summary_df[\"well_resourced_score\"].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "overall_stats = pd.DataFrame({\n",
    "    \"SA4 Region\": [\"Overall\"],\n",
    "    \"Mean Score\": [summary_df[\"well_resourced_score\"].mean()],\n",
    "    \"Median Score\": [summary_df[\"well_resourced_score\"].median()],\n",
    "    \"Standard Deviation\": [summary_df[\"well_resourced_score\"].std()],\n",
    "    \"IQR\": [iqr]\n",
    "})\n",
    "\n",
    "def calc_iqr(group):\n",
    "    q1 = group.quantile(0.25)\n",
    "    q3 = group.quantile(0.75)\n",
    "    return q3 - q1\n",
    "\n",
    "cross_zone_summary = summary_df.groupby(\"sa4_name_2021\")[\"well_resourced_score\"].agg(\n",
    "    mean=\"mean\",\n",
    "    median=\"median\",\n",
    "    std=\"std\",\n",
    "    iqr=calc_iqr\n",
    ").reset_index()\n",
    "\n",
    "cross_zone_summary.columns = [\"SA4 Region\", \"Mean Score\", \"Median Score\", \"Standard Deviation\", \"IQR\"]\n",
    "\n",
    "combined_summary = pd.concat([overall_stats, cross_zone_summary], ignore_index=True)\n",
    "\n",
    "display(combined_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca4b24-cd68-4a89-91a8-5307a989d67e",
   "metadata": {},
   "source": [
    "### 4.3 Cross-Zone Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b38480-2597-4588-9146-8e844ffaebb8",
   "metadata": {},
   "source": [
    "### 4.3 Cross-Zone Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858cc46a-8d3e-439b-ad04-92089dfdfed5",
   "metadata": {},
   "source": [
    "Compares the distribution of \"well-resourced scores\" across different SA4 zones. A boxplot visualization is used to illustrate differences or similarities in score distributions between these broader geographical areas, highlighting any systematic regional variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c31987c-4f72-4074-806d-cedb8c91b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.read_sql(text(\"\"\"\n",
    "    SELECT\n",
    "        public.sa2_summary.sa2_name,\n",
    "        well_resourced_score,\n",
    "        sa4_name_2021\n",
    "    FROM public.sa2_summary\n",
    "    JOIN public.sa2_regions USING (sa2_code)\n",
    "\"\"\"), conn)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(data=scores_df, x='sa4_name_2021', y='well_resourced_score',\n",
    "            hue='sa4_name_2021', palette='pastel')\n",
    "plt.title('Score Distribution by SA4 Zone')\n",
    "plt.xlabel('SA4 Zone')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975a927-7ecd-4d23-b7ba-711e1f441379",
   "metadata": {},
   "source": [
    "### 4.4 Noteworthy Patterns & Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58ed51-e1e7-468a-b7c1-ab87840cb31e",
   "metadata": {},
   "source": [
    "Identifies and visualizes the SA2 regions with the highest and lowest \"well-resourced scores.\" A bar chart displays the top 5 and bottom 5 performing regions, allowing for a quick understanding of the extremes in resource distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b1bb2d-1645-4dd4-b1c8-9b30be5dabbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = components_df.nlargest(5, 'well_resourced_score')\n",
    "bottom_5 = components_df.nsmallest(5, 'well_resourced_score')\n",
    "\n",
    "top_5['category'] = 'Top 5'\n",
    "bottom_5['category'] = 'Bottom 5'\n",
    "top_bottom_df = pd.concat([top_5, bottom_5])\n",
    "\n",
    "top_bottom_df = top_bottom_df.sort_values('well_resourced_score')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(data=top_bottom_df,\n",
    "                x='well_resourced_score',\n",
    "                y='sa2_name',\n",
    "                hue='category',\n",
    "                palette={'Top 5': 'forestgreen', 'Bottom 5': 'firebrick'},\n",
    "                dodge=False)\n",
    "\n",
    "for i, v in enumerate(top_bottom_df['well_resourced_score']):\n",
    "    ax.text(v + 0.01, i, f'{v:.2f}', va='center')\n",
    "\n",
    "plt.title('Top and Bottom 5 Performing SA2 Regions', fontsize=14)\n",
    "plt.xlabel('Well-Resourced Score', fontsize=12)\n",
    "plt.ylabel('SA2 Region', fontsize=12)\n",
    "plt.xlim(0, max(top_bottom_df['well_resourced_score']) * 1.1)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.legend(title='', loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f5499a-5502-4f5b-8700-d865e7abd534",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01a56f3-720f-4305-9d28-bbec2314268e",
   "metadata": {},
   "source": [
    "This section investigates the relationship between the \"well-resourced scores\" and socio-economic factors, specifically median income."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0572669b-ecd1-4bc8-9e84-741d785afa77",
   "metadata": {},
   "source": [
    "### 5.1 r & p-Value Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b9ef3-9cc5-4c7f-ac00-5a47e060f6ff",
   "metadata": {},
   "source": [
    "Calculates the Pearson correlation coefficient (r) and p-value to assess the statistical relationship between \"well-resourced scores\" and median income. This is performed for all SA2 regions combined and then separately for SA2 regions within specific SA4 zones (\"Sydney - Blacktown\", \"Sydney - Parramatta\", \"Sydney - Ryde\") to identify if the correlation varies by larger geographical area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d348b-5ddf-42ae-b122-6ec574a970d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_df_raw = query(\n",
    "    conn,\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "      s.sa2_name,\n",
    "      r.sa4_name_2021,\n",
    "      s.well_resourced_score,\n",
    "      i.median_income\n",
    "    FROM sa2_summary AS s\n",
    "    JOIN income       AS i USING (sa2_name)\n",
    "    JOIN sa2_regions  AS r USING (sa2_name)\n",
    "    \"\"\"\n",
    ")\n",
    "print(f\"Rows fetched from SQL: {len(summary_df_raw)}\")\n",
    "\n",
    "# Handle potential non-string median_income before .str.replace\n",
    "summary_df = summary_df_raw.copy() # Work on a copy\n",
    "summary_df[\"median_income\"] = summary_df[\"median_income\"].astype(str).str.replace(\",\", \"\")\n",
    "summary_df[\"median_income\"] = pd.to_numeric(\n",
    "    summary_df[\"median_income\"],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "print(f\"Rows after median_income numeric conversion: {len(summary_df)}\")\n",
    "print(f\"NaNs in median_income after coercion: {summary_df['median_income'].isna().sum()}\")\n",
    "print(f\"NaNs in well_resourced_score: {summary_df['well_resourced_score'].isna().sum()}\")\n",
    "\n",
    "summary_df = summary_df.dropna(subset=[\"well_resourced_score\", \"median_income\"])\n",
    "print(f\"Rows after dropping NaNs for correlation: {len(summary_df)}\")\n",
    "\n",
    "r_overall, p_overall = pearsonr(\n",
    "    summary_df[\"well_resourced_score\"],\n",
    "    summary_df[\"median_income\"]\n",
    ")\n",
    "print(f\"Overall (n={len(summary_df)}): Pearson r = {r_overall:.3f}, p = {p_overall:.3f}\")\n",
    "\n",
    "regions = [\"Sydney - Blacktown\", \"Sydney - Parramatta\", \"Sydney - Ryde\"]\n",
    "for region in regions:\n",
    "    sub = summary_df[summary_df[\"sa4_name_2021\"] == region]\n",
    "    r, p = pearsonr(sub[\"well_resourced_score\"], sub[\"median_income\"])\n",
    "    print(f\"{region} (n={len(sub)}): Pearson r = {r:.3f}, p = {p:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a98d2f-3d52-4293-ad12-638ea3be82f5",
   "metadata": {},
   "source": [
    "### 5.2 Regression plot of score vs. median income"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9172020b-e07d-4268-b7d6-a65980d1156e",
   "metadata": {},
   "source": [
    "Visualizes the relationship between \"well-resourced scores\" and median income using a scatter plot with an overlaid regression line. This plot helps to illustrate the direction and strength of the correlation, and the calculated Pearson correlation coefficient is annotated on the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a96bf2d-4571-46e4-af9d-042117811429",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.read_sql(text(\"\"\"\n",
    "    SELECT \n",
    "        ss.sa2_name,\n",
    "        ss.well_resourced_score,\n",
    "        i.median_income,\n",
    "        sr.sa4_name_2021\n",
    "    FROM public.sa2_summary ss\n",
    "    JOIN public.income i ON ss.sa2_code::text = i.sa2_code21::text\n",
    "    JOIN public.sa2_regions sr ON ss.sa2_code = sr.sa2_code\n",
    "\"\"\"), conn)\n",
    "\n",
    "corr_df['well_resourced_score'] = pd.to_numeric(corr_df['well_resourced_score'], errors='coerce')\n",
    "corr_df['median_income'] = pd.to_numeric(corr_df['median_income'], errors='coerce')\n",
    "\n",
    "corr_df = corr_df.dropna(subset=['well_resourced_score', 'median_income'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(data=corr_df, \n",
    "            x='well_resourced_score', \n",
    "            y='median_income',\n",
    "            scatter_kws={'alpha': 0.6},\n",
    "            line_kws={'color': 'red'})\n",
    "\n",
    "plt.title('Well-Resourced Score vs Median Income')\n",
    "plt.xlabel('Well-Resourced Score')\n",
    "plt.ylabel('Median Income ($)')\n",
    "plt.grid(True)\n",
    "\n",
    "# Calculate correlation coefficient\n",
    "correlation = corr_df['well_resourced_score'].corr(corr_df['median_income'])\n",
    "plt.annotate(f'Correlation: {correlation:.2f}', \n",
    "             xy=(0.05, 0.95), \n",
    "             xycoords='axes fraction',\n",
    "             bbox=dict(boxstyle=\"round\", facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb4bb76-2811-43b8-bf6b-4bc9e1c92488",
   "metadata": {},
   "source": [
    "## 6. Geographic Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842b79f7-8c17-40d4-947a-9c62d15b0599",
   "metadata": {},
   "source": [
    "### 6.1 Static Choropleth Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b55bf-2cf0-45cd-8993-678eaca15a7d",
   "metadata": {},
   "source": [
    "Creates a static choropleth map displaying the \"well-resourced scores\" for SA2 regions within selected SA4 zones (\"Sydney - Blacktown\", \"Sydney - Parramatta\", \"Sydney - Ryde\"). Scores are represented by a color gradient, SA4 boundaries are overlaid for context, and a basemap is included to provide geographic reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c675d3b-9f87-4f44-97f7-f24dcf3838cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df = gpd.read_postgis(text(\"\"\"\n",
    "    SELECT\n",
    "        sr.sa2_code,\n",
    "        sr.sa2_name,\n",
    "        sr.geometry,\n",
    "        ss.well_resourced_score,\n",
    "        sr.sa4_name_2021\n",
    "    FROM public.sa2_regions sr\n",
    "    JOIN public.sa2_summary ss ON sr.sa2_code = ss.sa2_code\n",
    "    WHERE sr.sa4_name_2021 IN ('Sydney - Blacktown', 'Sydney - Parramatta', 'Sydney - Ryde')\n",
    "\"\"\"), conn, geom_col='geometry')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "map_df.plot(column='well_resourced_score',\n",
    "            ax=ax,\n",
    "            legend=True,\n",
    "            legend_kwds={'label': \"Well-Resourced Score\", 'shrink': 0.5},\n",
    "            cmap='RdYlGn',\n",
    "            edgecolor='black',\n",
    "            linewidth=0.3,\n",
    "            missing_kwds={'color': 'lightgrey'})\n",
    "\n",
    "sa4_boundaries = gpd.read_postgis(text(\"\"\"\n",
    "    SELECT\n",
    "        sa4_name_2021,\n",
    "        ST_Union(geometry) as geometry\n",
    "    FROM public.sa2_regions\n",
    "    WHERE sa4_name_2021 IN ('Sydney - Blacktown', 'Sydney - Parramatta', 'Sydney - Ryde')\n",
    "    GROUP BY sa4_name_2021\n",
    "\"\"\"), conn, geom_col='geometry')\n",
    "\n",
    "sa4_boundaries.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=1.5)\n",
    "\n",
    "for idx, row in sa4_boundaries.iterrows():\n",
    "    ax.annotate(text=row['sa4_name_2021'],\n",
    "                xy=row['geometry'].centroid.coords[0],\n",
    "                ha='center',\n",
    "                fontsize=10,\n",
    "                bbox=dict(boxstyle=\"round\", facecolor='white', alpha=0.7))\n",
    "\n",
    "ctx.add_basemap(ax, crs=map_df.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n",
    "\n",
    "plt.title('Well-Resourced Scores by SA2 Region')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8c2705-3f1f-443b-8156-ff99fa5be5e5",
   "metadata": {},
   "source": [
    "### 6.2 Interactive Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf16d2e-1e5d-424b-8c51-cafe28f7e91a",
   "metadata": {},
   "source": [
    "Generates an interactive choropleth map using Folium to visualize \"well-resourced scores.\" The map includes features like hover tooltips displaying SA2 name, score, and SA4 region; multiple basemap options; a custom color legend; marker clusters for the top 5 regions; a title; layer control; fullscreen capability; and a measure tool for enhanced exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60700a60-5817-4fe4-9bbf-abbc887159fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[-33.8, 151.0], zoom_start=11, tiles='cartodbpositron')\n",
    "\n",
    "folium.TileLayer('cartodbpositron', name='Light Map').add_to(m)\n",
    "folium.TileLayer('cartodbdark_matter', name='Dark Map').add_to(m)\n",
    "folium.TileLayer('OpenStreetMap', name='OpenStreetMap').add_to(m)\n",
    "folium.TileLayer('Stamen Terrain', name='Terrain').add_to(m)\n",
    "\n",
    "def get_color(score):\n",
    "    if score is None:\n",
    "        return '#CCCCCC'\n",
    "    elif score >= 0.8:\n",
    "        return '#1a9850'\n",
    "    elif score >= 0.6:\n",
    "        return '#91cf60'\n",
    "    elif score >= 0.4:\n",
    "        return '#ffffbf'\n",
    "    elif score >= 0.2:\n",
    "        return '#fc8d59'\n",
    "    else:\n",
    "        return '#d73027'\n",
    "\n",
    "def style_function(feature):\n",
    "    score = feature['properties']['well_resourced_score']\n",
    "    return {\n",
    "        'fillColor': get_color(score),\n",
    "        'color': 'black',\n",
    "        'weight': 1,\n",
    "        'fillOpacity': 0.7\n",
    "    }\n",
    "\n",
    "def highlight_function(feature):\n",
    "    return {\n",
    "        'weight': 3,\n",
    "        'color': '#666',\n",
    "        'dashArray': '',\n",
    "        'fillOpacity': 0.9\n",
    "    }\n",
    "\n",
    "choropleth = folium.GeoJson(\n",
    "    map_df,\n",
    "    name='Well-Resourced Scores',\n",
    "    style_function=style_function,\n",
    "    highlight_function=highlight_function,\n",
    "    tooltip=folium.GeoJsonTooltip(\n",
    "        fields=['sa2_name', 'well_resourced_score', 'sa4_name_2021'],\n",
    "        aliases=['Area:', 'Score:', 'Region:'],\n",
    "        localize=True,\n",
    "        sticky=True,\n",
    "        labels=True,\n",
    "        style=\"\"\"\n",
    "            background-color: #F0EFEF;\n",
    "            border: 2px solid black;\n",
    "            border-radius: 3px;\n",
    "            box-shadow: 3px 3px 3px rgba(0,0,0,0.4);\n",
    "            font-size: 14px;\n",
    "            padding: 10px;\n",
    "        \"\"\"\n",
    "    )\n",
    ").add_to(m)\n",
    "\n",
    "legend_html = '''\n",
    "    <div style=\"position: fixed;\n",
    "        bottom: 50px; right: 50px; width: 180px; height: 170px;\n",
    "        border:2px solid grey; z-index:9999; font-size:14px;\n",
    "        background-color: white; padding: 10px; border-radius: 5px\">\n",
    "    <p style=\"margin-top: 0; margin-bottom: 5px;\"><b>Well-Resourced Score</b></p>\n",
    "    <div style=\"display: flex; align-items: center; margin-bottom: 5px;\">\n",
    "        <span style=\"background-color:#1a9850; width:20px; height:20px; display:inline-block; margin-right:5px;\"></span>\n",
    "        <span>0.8 - 1.0</span>\n",
    "    </div>\n",
    "    <div style=\"display: flex; align-items: center; margin-bottom: 5px;\">\n",
    "        <span style=\"background-color:#91cf60; width:20px; height:20px; display:inline-block; margin-right:5px;\"></span>\n",
    "        <span>0.6 - 0.8</span>\n",
    "    </div>\n",
    "    <div style=\"display: flex; align-items: center; margin-bottom: 5px;\">\n",
    "        <span style=\"background-color:#ffffbf; width:20px; height:20px; display:inline-block; margin-right:5px;\"></span>\n",
    "        <span>0.4 - 0.6</span>\n",
    "    </div>\n",
    "    <div style=\"display: flex; align-items: center; margin-bottom: 5px;\">\n",
    "        <span style=\"background-color:#fc8d59; width:20px; height:20px; display:inline-block; margin-right:5px;\"></span>\n",
    "        <span>0.2 - 0.4</span>\n",
    "    </div>\n",
    "    <div style=\"display: flex; align-items: center; margin-bottom: 5px;\">\n",
    "        <span style=\"background-color:#d73027; width:20px; height:20px; display:inline-block; margin-right:5px;\"></span>\n",
    "        <span>0.0 - 0.2</span>\n",
    "    </div>\n",
    "    </div>\n",
    "'''\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "marker_cluster = MarkerCluster(name=\"Top Regions\").add_to(m)\n",
    "\n",
    "top_regions = map_df.nlargest(5, 'well_resourced_score')\n",
    "for idx, row in top_regions.iterrows():\n",
    "    centroid = row['geometry'].centroid\n",
    "    popup_text = f\"\"\"\n",
    "    <b>{row['sa2_name']}</b><br>\n",
    "    Score: {row['well_resourced_score']:.2f}<br>\n",
    "    Region: {row['sa4_name_2021']}\n",
    "    \"\"\"\n",
    "\n",
    "    folium.Marker(\n",
    "        location=[centroid.y, centroid.x],\n",
    "        popup=folium.Popup(popup_text, max_width=300),\n",
    "        icon=folium.Icon(color='green', icon='star', prefix='fa'),\n",
    "        tooltip=f\"Top Region: {row['sa2_name']}\"\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "title_html = '''\n",
    "    <div style=\"position: fixed;\n",
    "        top: 10px; left: 50%; transform: translateX(-50%);\n",
    "        z-index:9999; font-size:18px; font-weight: bold;\n",
    "        background-color: white; padding: 10px; border-radius: 5px;\n",
    "        border:2px solid grey; text-align: center;\">\n",
    "        Well-Resourced Scores by SA2 Region - Sydney\n",
    "    </div>\n",
    "'''\n",
    "m.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "from folium.plugins import Fullscreen\n",
    "Fullscreen().add_to(m)\n",
    "\n",
    "from folium.plugins import MeasureControl\n",
    "m.add_child(MeasureControl(position='topleft', primary_length_unit='kilometers'))\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed94ae46-abe1-4281-909c-c3b786313956",
   "metadata": {},
   "source": [
    "## 7. Scrutiny of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48ec12-4138-491f-99e3-73cda1438a5b",
   "metadata": {},
   "source": [
    "### 7.1 Sensitivity testing \n",
    "Assesses the impact of individual components (z_business, z_stops, z_schools, z_poi) on the final \"well-resourced score\" and its ranking. This involves:\n",
    "1. Calculating the direct Pearson correlation of each component's z-score with the composite score.\n",
    "2. Performing a leave-one-out analysis: each component is temporarily removed, the composite score is recalculated, and the Spearman rank correlation between the original ranking and the new ranking is computed.\n",
    "3. Comparing distributional statistics (mean, median, standard deviation) of the original composite score with those of scores recalculated after dropping each component.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24fa08-bddd-424f-9226-2da13ca75845",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT\n",
    "  s.sa2_name,\n",
    "  r.sa4_name_2021,\n",
    "  s.well_resourced_score,\n",
    "  s.z_business,\n",
    "  s.z_stops,\n",
    "  s.z_schools,\n",
    "  s.z_poi,\n",
    "  i.median_income\n",
    "FROM sa2_summary AS s\n",
    "JOIN income     AS i USING (sa2_name)\n",
    "JOIN sa2_regions AS r USING (sa2_name)\n",
    "\"\"\"\n",
    "df = query(conn, sql).dropna()\n",
    "\n",
    "df[\"median_income\"] = df[\"median_income\"].str.replace(\",\", \"\")\n",
    "df[\"median_income\"] = pd.to_numeric(df[\"median_income\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"well_resourced_score\", \"median_income\"])\n",
    "\n",
    "components    = [\"z_business\", \"z_stops\", \"z_schools\", \"z_poi\"]\n",
    "composite_col = \"well_resourced_score\"\n",
    "\n",
    "print(\"1) Direct Pearson correlations with final score:\")\n",
    "for comp in components:\n",
    "    r, p = pearsonr(df[comp], df[composite_col])\n",
    "    print(f\"   {comp:>12s} → r = {r:.3f}, p = {p:.3f}\")\n",
    "\n",
    "orig_rank = df[composite_col].rank(method=\"average\")\n",
    "print(\"\\n2) Leave-one-out Spearman rank correlations:\")\n",
    "for comp in components:\n",
    "    others   = [c for c in components if c != comp]\n",
    "    raw_sum  = df[others].sum(axis=1)\n",
    "    mod_score = 1 / (1 + np.exp(-raw_sum))\n",
    "    mod_rank  = mod_score.rank(method=\"average\")\n",
    "    rho, p    = spearmanr(orig_rank, mod_rank)\n",
    "    print(f\"   without {comp:>8s} → ρ = {rho:.3f}, p = {p:.3f}\")\n",
    "\n",
    "orig_stats = (\n",
    "    df[composite_col].mean(),\n",
    "    df[composite_col].median(),\n",
    "    df[composite_col].std()\n",
    ")\n",
    "print(\"\\n3) Distribution statistics comparison (mean, median, std):\")\n",
    "print(f\"   original       : mean = {orig_stats[0]:.3f}, median = {orig_stats[1]:.3f}, std = {orig_stats[2]:.3f}\")\n",
    "for comp in components:\n",
    "    others    = [c for c in components if c != comp]\n",
    "    raw_sum   = df[others].sum(axis=1)\n",
    "    mod_score = 1 / (1 + np.exp(-raw_sum))\n",
    "    stats     = (mod_score.mean(), np.median(mod_score), mod_score.std())\n",
    "    print(f\"   without {comp:>8s} : mean = {stats[0]:.3f}, median = {stats[1]:.3f}, std = {stats[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb4d7b-d6b6-41a7-9178-df3e3087764c",
   "metadata": {},
   "source": [
    "## OUR UNSTRUCTURED CODES ⤵️\n",
    "-- MOVE UP YOUR CODE INTO THEIR SECTIONS --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f917945-5f1a-4fd1-8462-a95ba0397c4b",
   "metadata": {},
   "source": [
    "## Setup and Connection\n",
    "### Imports  \n",
    "Load all Python libraries used in Task 1:  \n",
    "* **pandas / geopandas** for data wrangling  \n",
    "* **sqlalchemy + psycopg2** to talk to Postgres/PostGIS  \n",
    "* **geoalchemy2.Geometry** helper so geopandas can write geometries  \n",
    "* a few plotting + shapely utilities for quick inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b1d6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import geopandas as gpd \n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a27ba92-b260-4f54-96ba-0688ea4b9e53",
   "metadata": {},
   "source": [
    "### Build a reusable PostgreSQL connector  \n",
    "`pgconnect()` opens an SQLAlchemy engine from *Credentials.json*.  \n",
    "The helper `query()` lets us run quick SQL and return a dataframe.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25eebed4-e912-45d9-b253-6b0dfc296b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "credentials = \"Credentials.json\"\n",
    "def pgconnect(credential_filepath, db_schema=\"public\"):\n",
    "    \"\"\"\n",
    "    Reads credentials.json, prefers the 'database' key, then 'dbname',\n",
    "    then falls back to the user. Returns (engine, connection).\n",
    "    \"\"\"\n",
    "    with open(credential_filepath, \"r\") as f:\n",
    "        creds = json.load(f)\n",
    "\n",
    "    host   = creds[\"host\"]\n",
    "    port   = creds[\"port\"]\n",
    "    user   = creds[\"user\"]\n",
    "    pw     = creds[\"password\"]\n",
    "    dbname = creds.get(\"database\") or creds.get(\"dbname\") or user\n",
    "\n",
    "    url = f\"postgresql+psycopg2://{user}:{pw}@{host}:{port}/{dbname}\"\n",
    "\n",
    "    try:\n",
    "        engine = create_engine(url, echo=False)\n",
    "        conn   = engine.connect()\n",
    "        print(f\"Connected successfully to '{dbname}'.\")\n",
    "    except Exception as e:\n",
    "        print(\"Unable to connect to the database:\")\n",
    "        print(e)\n",
    "        engine, conn = None, None\n",
    "\n",
    "    return engine, conn\n",
    "\n",
    "def query(engine, sqlcmd, args=None, df=True):\n",
    "    \"\"\"\n",
    "    Convenience wrapper around pandas.read_sql_query or raw execute.\n",
    "    - If df=True: returns a DataFrame via pandas.read_sql_query()\n",
    "    - Else: runs a raw execute() on engine and returns fetched results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if df:\n",
    "            return pd.read_sql_query(sqlcmd, engine, params=args)\n",
    "        else:\n",
    "            result = engine.execute(text(sqlcmd), args).fetchall()\n",
    "            return result[0] if len(result) == 1 else result\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81294f12-3f47-400a-a614-dee6d794356e",
   "metadata": {},
   "source": [
    "### Connect to the database  \n",
    "Runs `pgconnect()` – if you see **“Connected successfully.”** the engine + connection are ready.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9b8e4e3-354e-43a6-8041-7e872c3e3b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to connect to the database:\n",
      "(psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  database \"localhost\" does not exist\n",
      "\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "db, conn = pgconnect(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc7f47d-e532-47c4-b318-8fb674a1300d",
   "metadata": {},
   "source": [
    "### Sanity check: confirm PostGIS is installed  \n",
    "Queries `PostGIS_Version()`; if it returns a version string, spatial functions are available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1508831f-5a85-42c9-8b8c-65852827edff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered: 'NoneType' object has no attribute 'cursor'\n"
     ]
    }
   ],
   "source": [
    "query(conn, \"select PostGIS_Version()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1135ace2-bfff-4eee-8051-81f400c86e26",
   "metadata": {},
   "source": [
    "## Load Datas\n",
    "###  Read Business, Population, Income CSVs \n",
    "Read the three non-spatial CSV files into pandas dataframes.  \n",
    "At this point we only preview them; they get written to Postgres later with `to_sql()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "068986b5-db1c-4f9f-9d09-19432f5c4b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>industry_code</th>\n",
       "      <th>industry_name</th>\n",
       "      <th>sa2_code</th>\n",
       "      <th>sa2_name</th>\n",
       "      <th>0_to_50k_businesses</th>\n",
       "      <th>50k_to_200k_businesses</th>\n",
       "      <th>200k_to_2m_businesses</th>\n",
       "      <th>2m_to_5m_businesses</th>\n",
       "      <th>5m_to_10m_businesses</th>\n",
       "      <th>10m_or_more_businesses</th>\n",
       "      <th>total_businesses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Agriculture, Forestry and Fishing</td>\n",
       "      <td>101021007</td>\n",
       "      <td>Braidwood</td>\n",
       "      <td>136</td>\n",
       "      <td>92</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>Agriculture, Forestry and Fishing</td>\n",
       "      <td>101021008</td>\n",
       "      <td>Karabar</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Agriculture, Forestry and Fishing</td>\n",
       "      <td>101021009</td>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>Agriculture, Forestry and Fishing</td>\n",
       "      <td>101021010</td>\n",
       "      <td>Queanbeyan - East</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>Agriculture, Forestry and Fishing</td>\n",
       "      <td>101021012</td>\n",
       "      <td>Queanbeyan West - Jerrabomberra</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  industry_code                      industry_name   sa2_code  \\\n",
       "0             A  Agriculture, Forestry and Fishing  101021007   \n",
       "1             A  Agriculture, Forestry and Fishing  101021008   \n",
       "2             A  Agriculture, Forestry and Fishing  101021009   \n",
       "3             A  Agriculture, Forestry and Fishing  101021010   \n",
       "4             A  Agriculture, Forestry and Fishing  101021012   \n",
       "\n",
       "                          sa2_name  0_to_50k_businesses  \\\n",
       "0                        Braidwood                  136   \n",
       "1                          Karabar                    6   \n",
       "2                       Queanbeyan                    6   \n",
       "3                Queanbeyan - East                    0   \n",
       "4  Queanbeyan West - Jerrabomberra                    7   \n",
       "\n",
       "   50k_to_200k_businesses  200k_to_2m_businesses  2m_to_5m_businesses  \\\n",
       "0                      92                     63                    4   \n",
       "1                       3                      0                    0   \n",
       "2                       4                      3                    0   \n",
       "3                       3                      0                    0   \n",
       "4                       4                      5                    0   \n",
       "\n",
       "   5m_to_10m_businesses  10m_or_more_businesses  total_businesses  \n",
       "0                     0                       0               296  \n",
       "1                     0                       0                 9  \n",
       "2                     0                       3                15  \n",
       "3                     0                       0                 3  \n",
       "4                     0                       0                16  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business = pd.read_csv(\"data/Businesses.csv\")\n",
    "business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67a49c5b-123d-4d79-b4a3-a515c53e2d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sa2_code21</th>\n",
       "      <th>sa2_name</th>\n",
       "      <th>earners</th>\n",
       "      <th>median_age</th>\n",
       "      <th>median_income</th>\n",
       "      <th>mean_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101021007</td>\n",
       "      <td>Braidwood</td>\n",
       "      <td>2467</td>\n",
       "      <td>51</td>\n",
       "      <td>46640</td>\n",
       "      <td>68904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101021008</td>\n",
       "      <td>Karabar</td>\n",
       "      <td>5103</td>\n",
       "      <td>42</td>\n",
       "      <td>65564</td>\n",
       "      <td>69672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101021009</td>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>7028</td>\n",
       "      <td>39</td>\n",
       "      <td>63528</td>\n",
       "      <td>69174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101021010</td>\n",
       "      <td>Queanbeyan - East</td>\n",
       "      <td>3398</td>\n",
       "      <td>39</td>\n",
       "      <td>66148</td>\n",
       "      <td>74162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101021012</td>\n",
       "      <td>Queanbeyan West - Jerrabomberra</td>\n",
       "      <td>8422</td>\n",
       "      <td>44</td>\n",
       "      <td>78630</td>\n",
       "      <td>91981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sa2_code21                         sa2_name earners median_age  \\\n",
       "0   101021007                        Braidwood    2467         51   \n",
       "1   101021008                          Karabar    5103         42   \n",
       "2   101021009                       Queanbeyan    7028         39   \n",
       "3   101021010                Queanbeyan - East    3398         39   \n",
       "4   101021012  Queanbeyan West - Jerrabomberra    8422         44   \n",
       "\n",
       "  median_income mean_income  \n",
       "0         46640       68904  \n",
       "1         65564       69672  \n",
       "2         63528       69174  \n",
       "3         66148       74162  \n",
       "4         78630       91981  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income = pd.read_csv(\"data/income.csv\")\n",
    "income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f55b935c-f004-4296-8240-8e0b02e0a4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sa2_code</th>\n",
       "      <th>sa2_name</th>\n",
       "      <th>0-4_people</th>\n",
       "      <th>5-9_people</th>\n",
       "      <th>10-14_people</th>\n",
       "      <th>15-19_people</th>\n",
       "      <th>20-24_people</th>\n",
       "      <th>25-29_people</th>\n",
       "      <th>30-34_people</th>\n",
       "      <th>35-39_people</th>\n",
       "      <th>...</th>\n",
       "      <th>45-49_people</th>\n",
       "      <th>50-54_people</th>\n",
       "      <th>55-59_people</th>\n",
       "      <th>60-64_people</th>\n",
       "      <th>65-69_people</th>\n",
       "      <th>70-74_people</th>\n",
       "      <th>75-79_people</th>\n",
       "      <th>80-84_people</th>\n",
       "      <th>85-and-over_people</th>\n",
       "      <th>total_people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102011028</td>\n",
       "      <td>Avoca Beach - Copacabana</td>\n",
       "      <td>424</td>\n",
       "      <td>522</td>\n",
       "      <td>623</td>\n",
       "      <td>552</td>\n",
       "      <td>386</td>\n",
       "      <td>222</td>\n",
       "      <td>306</td>\n",
       "      <td>416</td>\n",
       "      <td>...</td>\n",
       "      <td>572</td>\n",
       "      <td>602</td>\n",
       "      <td>570</td>\n",
       "      <td>520</td>\n",
       "      <td>464</td>\n",
       "      <td>369</td>\n",
       "      <td>226</td>\n",
       "      <td>142</td>\n",
       "      <td>70</td>\n",
       "      <td>7530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102011029</td>\n",
       "      <td>Box Head - MacMasters Beach</td>\n",
       "      <td>511</td>\n",
       "      <td>666</td>\n",
       "      <td>702</td>\n",
       "      <td>592</td>\n",
       "      <td>461</td>\n",
       "      <td>347</td>\n",
       "      <td>420</td>\n",
       "      <td>535</td>\n",
       "      <td>...</td>\n",
       "      <td>749</td>\n",
       "      <td>749</td>\n",
       "      <td>794</td>\n",
       "      <td>895</td>\n",
       "      <td>863</td>\n",
       "      <td>925</td>\n",
       "      <td>603</td>\n",
       "      <td>331</td>\n",
       "      <td>264</td>\n",
       "      <td>11052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102011030</td>\n",
       "      <td>Calga - Kulnura</td>\n",
       "      <td>200</td>\n",
       "      <td>225</td>\n",
       "      <td>258</td>\n",
       "      <td>278</td>\n",
       "      <td>274</td>\n",
       "      <td>227</td>\n",
       "      <td>214</td>\n",
       "      <td>286</td>\n",
       "      <td>...</td>\n",
       "      <td>325</td>\n",
       "      <td>436</td>\n",
       "      <td>422</td>\n",
       "      <td>397</td>\n",
       "      <td>327</td>\n",
       "      <td>264</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "      <td>75</td>\n",
       "      <td>4748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102011031</td>\n",
       "      <td>Erina - Green Point</td>\n",
       "      <td>683</td>\n",
       "      <td>804</td>\n",
       "      <td>880</td>\n",
       "      <td>838</td>\n",
       "      <td>661</td>\n",
       "      <td>502</td>\n",
       "      <td>587</td>\n",
       "      <td>757</td>\n",
       "      <td>...</td>\n",
       "      <td>859</td>\n",
       "      <td>882</td>\n",
       "      <td>901</td>\n",
       "      <td>930</td>\n",
       "      <td>917</td>\n",
       "      <td>1065</td>\n",
       "      <td>976</td>\n",
       "      <td>773</td>\n",
       "      <td>1028</td>\n",
       "      <td>14803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102011032</td>\n",
       "      <td>Gosford - Springfield</td>\n",
       "      <td>1164</td>\n",
       "      <td>1044</td>\n",
       "      <td>1084</td>\n",
       "      <td>1072</td>\n",
       "      <td>1499</td>\n",
       "      <td>1864</td>\n",
       "      <td>1750</td>\n",
       "      <td>1520</td>\n",
       "      <td>...</td>\n",
       "      <td>1330</td>\n",
       "      <td>1241</td>\n",
       "      <td>1377</td>\n",
       "      <td>1285</td>\n",
       "      <td>1166</td>\n",
       "      <td>949</td>\n",
       "      <td>664</td>\n",
       "      <td>476</td>\n",
       "      <td>537</td>\n",
       "      <td>21346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sa2_code                     sa2_name  0-4_people  5-9_people  \\\n",
       "0  102011028     Avoca Beach - Copacabana         424         522   \n",
       "1  102011029  Box Head - MacMasters Beach         511         666   \n",
       "2  102011030              Calga - Kulnura         200         225   \n",
       "3  102011031          Erina - Green Point         683         804   \n",
       "4  102011032        Gosford - Springfield        1164        1044   \n",
       "\n",
       "   10-14_people  15-19_people  20-24_people  25-29_people  30-34_people  \\\n",
       "0           623           552           386           222           306   \n",
       "1           702           592           461           347           420   \n",
       "2           258           278           274           227           214   \n",
       "3           880           838           661           502           587   \n",
       "4          1084          1072          1499          1864          1750   \n",
       "\n",
       "   35-39_people  ...  45-49_people  50-54_people  55-59_people  60-64_people  \\\n",
       "0           416  ...           572           602           570           520   \n",
       "1           535  ...           749           749           794           895   \n",
       "2           286  ...           325           436           422           397   \n",
       "3           757  ...           859           882           901           930   \n",
       "4          1520  ...          1330          1241          1377          1285   \n",
       "\n",
       "   65-69_people  70-74_people  75-79_people  80-84_people  85-and-over_people  \\\n",
       "0           464           369           226           142                  70   \n",
       "1           863           925           603           331                 264   \n",
       "2           327           264           190           100                  75   \n",
       "3           917          1065           976           773                1028   \n",
       "4          1166           949           664           476                 537   \n",
       "\n",
       "   total_people  \n",
       "0          7530  \n",
       "1         11052  \n",
       "2          4748  \n",
       "3         14803  \n",
       "4         21346  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population = pd.read_csv(\"data/Population.csv\")\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb88901c-1963-4863-8846-4fbb90b6c58c",
   "metadata": {},
   "source": [
    "### Define Table Schemas in SQL  \n",
    "* Raw SQL (**cell 7**) creates three empty spatial tables  \n",
    "  (`sa2_regions`, `stops`, `schools`) with geometry columns, SRID 4326,  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c57dc46f-562d-47f7-bda6-f3f0433bd445",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'execute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 23\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text \n\u001b[1;32m      2\u001b[0m create_sa2_sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mDROP TABLE IF EXISTS public.sa2_regions;\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mCREATE TABLE public.sa2_regions (\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 23\u001b[0m conn\u001b[38;5;241m.\u001b[39mexecute(text(create_sa2_sql))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'execute'"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text \n",
    "create_sa2_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS public.sa2_regions;\n",
    "CREATE TABLE public.sa2_regions (\n",
    "    sa2_code_2021 TEXT PRIMARY KEY,\n",
    "    sa2_name_2021 TEXT,\n",
    "    geometry      GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\n",
    "CREATE INDEX IF NOT EXISTS sa2_regions_geom_idx\n",
    "    ON public.sa2_regions USING GIST (geometry);\n",
    "\n",
    "DROP TABLE IF EXISTS public.stops;\n",
    "CREATE TABLE public.stops (\n",
    "    stop_id   TEXT PRIMARY KEY,\n",
    "    stop_name TEXT,\n",
    "    geometry  GEOMETRY(POINT,4326)\n",
    ");\n",
    "CREATE INDEX IF NOT EXISTS stops_geom_idx\n",
    "    ON public.stops USING GIST (geometry);\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(text(create_sa2_sql))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d829b111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02a7e6d2-affe-4523-927e-d8fc031683f3",
   "metadata": {},
   "source": [
    "### Load CSVs into Postgres with Pandas\n",
    "  primary keys, and GIST indexes.  \n",
    "* **cell 8** loops through *Businesses / Population / Income* dataframes  \n",
    "  and writes them to Postgres with `to_sql()`, then adds b-tree indexes on `sa2_code`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699f57d-3364-448f-8f70-64e4e8c37157",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_file, table in [\n",
    "    (\"data/Businesses.csv\", \"businesses\"),\n",
    "    (\"data/Population.csv\", \"population\"),\n",
    "    (\"data/Income.csv\", \"income\"),\n",
    "]:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.to_sql(\n",
    "        table,\n",
    "        conn,\n",
    "        schema = \"public\",\n",
    "        if_exists = \"replace\",\n",
    "        index = False,\n",
    "        method = \"multi\")\n",
    "    print(f\"Loaded {table}: {len(df)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b7ff50-4c5a-4606-9d4f-c6725bb7b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method A: using your helper\n",
    "cols = query(conn, \"\"\"\n",
    "    SELECT column_name\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_name='income'\n",
    "      AND table_schema='public';\n",
    "\"\"\")\n",
    "print(cols)\n",
    "\n",
    "# Method B: manually fetch\n",
    "result = conn.execute(text(\"\"\"\n",
    "    SELECT column_name\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_name='income'\n",
    "      AND table_schema='public';\n",
    "\"\"\"))\n",
    "print([row[0] for row in result.fetchall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a86fed-3f78-4e58-95b8-be8765553f4b",
   "metadata": {},
   "source": [
    "### Add b-tree indexes on `sa2_code`  \n",
    "Speeds up joins between attribute tables and spatial layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6074352-9d3f-4671-9d92-ee105f7481e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "    CREATE INDEX IF NOT EXISTS businesses_sa2_idx\n",
    "      ON public.businesses (sa2_code);\n",
    "    CREATE INDEX IF NOT EXISTS population_sa2_idx\n",
    "      ON public.population (sa2_code);\n",
    "    CREATE INDEX IF NOT EXISTS income_sa2_idx\n",
    "      ON public.income (sa2_code21);\n",
    "\"\"\"))\n",
    "print(\"Indexes created on sa2_code for all three tables.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa433ed9-da07-4b47-91ff-eca164931b42",
   "metadata": {},
   "source": [
    "## 3. Load Spatial Tables\n",
    "### Load SA2 boundaries shapefile  \n",
    "* Reads `SA2_2021_AUST_GDA2020.shp` with `gpd.read_file()`.  \n",
    "* Keeps only code, name, geometry; reprojects to WGS-84 (EPSG 4326).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4aba06-ebe6-4b35-a921-98e1a757796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load SA2 boundaries WITH SA4 + GCC columns --------------------------\n",
    "import geopandas as gpd\n",
    "from geoalchemy2 import Geometry\n",
    "from sqlalchemy import text\n",
    "\n",
    "# 1. Read shapefile and keep the extra admin columns\n",
    "sa2 = (\n",
    "    gpd.read_file(\"data/SA2_2021_AUST_SHP_GDA2020/SA2_2021_AUST_GDA2020.shp\")[\n",
    "        [\"SA2_CODE21\", \"SA2_NAME21\", \"SA4_NAME21\", \"GCC_NAME21\", \"geometry\"]\n",
    "    ]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"SA2_CODE21\": \"sa2_code\",\n",
    "            \"SA2_NAME21\": \"sa2_name\",\n",
    "            \"SA4_NAME21\": \"sa4_name_2021\",\n",
    "            \"GCC_NAME21\": \"gcc_name_2021\",\n",
    "        }\n",
    "    )\n",
    "    .to_crs(4326)\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "# 2. Re-create the table from scratch\n",
    "conn.execute(text(\"DROP TABLE IF EXISTS public.sa2_regions;\"))\n",
    "\n",
    "sa2.to_postgis(\n",
    "    \"sa2_regions\", conn,\n",
    "    schema=\"public\",\n",
    "    if_exists=\"replace\",            # overwrite\n",
    "    index=False,\n",
    "    dtype={\"geometry\": Geometry(\"MULTIPOLYGON\", 4326)}\n",
    ")\n",
    "\n",
    "# 3. Add PK and spatial index\n",
    "conn.execute(text(\"\"\"\n",
    "ALTER TABLE public.sa2_regions\n",
    "  ADD CONSTRAINT sa2_regions_pkey PRIMARY KEY (sa2_code);\n",
    "CREATE INDEX sa2_regions_geom_idx\n",
    "  ON public.sa2_regions USING GIST (geometry);\n",
    "\"\"\"))\n",
    "\n",
    "print(f\"Reloaded {len(sa2):,} SA2 polygons with SA4 & GCC info.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1942aa6a-bc52-42c4-a01c-1762468a2d1e",
   "metadata": {},
   "source": [
    "### Create Spatial Table for SA2 \n",
    "Drops any old copy and recreates `public.sa2_regions` with  \n",
    "`GEOMETRY(MULTIPOLYGON,4326)`, primary key `sa2_code_2021`, and GIST index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec6b33-7d0b-45ae-9d9b-cd1cde154306",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl = \"\"\"\n",
    "DROP TABLE IF EXISTS public.sa2_regions;\n",
    "CREATE TABLE public.sa2_regions (\n",
    "    sa2_code TEXT PRIMARY KEY,\n",
    "    sa2_name TEXT,\n",
    "    geometry GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\n",
    "CREATE INDEX IF NOT EXISTS sa2_regions_geom_idx\n",
    "  ON public.sa2_regions USING GIST (geometry);\n",
    "\"\"\"\n",
    "conn.execute(text(ddl))\n",
    "print(\"Spatial table sa2_regions created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6413237-90b6-4362-a2f1-ddd837083ec6",
   "metadata": {},
   "source": [
    "### Insert SA2 to PostGIS \n",
    "`to_postgis()` streams the GeoDataFrame into the empty table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a83b5-a03d-4acc-8728-28ef93f37204",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa2.to_postgis(\n",
    "    \"sa2_regions\", conn,\n",
    "    schema=\"public\",\n",
    "    if_exists=\"replace\",   \n",
    "    index=False,\n",
    "    dtype={\"geometry\": Geometry(\"MULTIPOLYGON\", 4326)}\n",
    ")\n",
    "print(f\"Inserted {len(sa2):,} SA2 rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c60e21-3232-4616-9de1-0b40ec7cc052",
   "metadata": {},
   "source": [
    "### Ensure SA2 Table Index Exists\n",
    "PL/pgSQL block only adds them if missing (useful if the cell is rerun).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3bf6af-a409-4220-937e-26a6bbce015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DO $$\n",
    "BEGIN\n",
    "  -- add PK only if it doesn't exist\n",
    "  IF NOT EXISTS (\n",
    "      SELECT 1 FROM pg_constraint\n",
    "      WHERE conname = 'sa2_regions_pkey'\n",
    "  ) THEN\n",
    "      ALTER TABLE public.sa2_regions\n",
    "        ADD CONSTRAINT sa2_regions_pkey PRIMARY KEY (sa2_code);\n",
    "  END IF;\n",
    "\n",
    "  -- add GIST index only if it doesn't exist\n",
    "  IF NOT EXISTS (\n",
    "      SELECT 1 FROM pg_indexes\n",
    "      WHERE schemaname = 'public'\n",
    "        AND tablename  = 'sa2_regions'\n",
    "        AND indexname  = 'sa2_regions_geom_idx'\n",
    "  ) THEN\n",
    "      CREATE INDEX sa2_regions_geom_idx\n",
    "        ON public.sa2_regions USING GIST (geometry);\n",
    "  END IF;\n",
    "END $$;\n",
    "\"\"\"))\n",
    "\n",
    "print(\"Primary key and GIST index verified/created.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d0b80",
   "metadata": {},
   "source": [
    "### Select SA2 polygons for my SA4 zone  \n",
    "The ABS shapefile stores the SA4 each SA2 belongs to.  \n",
    "Here we keep only SA2s that are:\n",
    "* inside the **Greater Sydney** GCC, and  \n",
    "* inside the SA4 zone we choose (set in `TARGET_SA4`).  \n",
    "\n",
    "The resulting GeoDataFrame `my_sa2` will drive every later step\n",
    "(spatial joins, POI API calls, scoring …).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e5ca53-41e7-4db2-b84e-9c22dd8b7aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"\"\"\n",
    "SELECT DISTINCT sa4_name_2021\n",
    "FROM   public.sa2_regions\n",
    "WHERE  gcc_name_2021 = 'Greater Sydney'\n",
    "ORDER  BY sa4_name_2021;\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba5446f-c8e0-4f89-a284-31f8d9ba8017",
   "metadata": {},
   "source": [
    "## Team Memember Hardik Chojar Chose \"Sydney - Parramatta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45945292",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SA4 = \"Sydney - Parramatta\"     \n",
    "\n",
    "my_sa2 = gpd.read_postgis(\n",
    "    \"\"\"\n",
    "    SELECT sa2_code,\n",
    "           sa2_name,\n",
    "           geometry\n",
    "    FROM   public.sa2_regions\n",
    "    WHERE  gcc_name_2021 = 'Greater Sydney'\n",
    "      AND  sa4_name_2021 = %(sa4)s\n",
    "    \"\"\",\n",
    "    conn,\n",
    "    geom_col=\"geometry\",\n",
    "    params={\"sa4\": TARGET_SA4}\n",
    ")\n",
    "\n",
    "print(f\"{len(my_sa2)} SA2s in {TARGET_SA4}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f209a096-e6e1-4de9-ac8e-7dfcb511bce4",
   "metadata": {},
   "source": [
    "## 4. Load Public Transport Stops\n",
    "### Load GTFS Stops and Convert to Geometry  \n",
    "* Reads `Stops.txt`, constructs a GeoDataFrame from lon/lat via  \n",
    "  `gpd.points_from_xy()`.  \n",
    "* Appends rows to `public.stops`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b3eca-72fd-4199-b14d-8e49830ce336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, geopandas as gpd\n",
    "from geoalchemy2 import Geometry\n",
    "\n",
    "# build GeoDataFrame\n",
    "stops = pd.read_csv(\"data/Stops.txt\")\n",
    "stops.drop_duplicates(inplace=True)\n",
    "\n",
    "stops_gdf = gpd.GeoDataFrame(\n",
    "    stops[[\"stop_id\",\"stop_name\"]],\n",
    "    geometry=gpd.points_from_xy(stops.stop_lon, stops.stop_lat),\n",
    "    crs=4326\n",
    ")\n",
    "\n",
    "# append rows\n",
    "stops_gdf.to_postgis(\"stops\", conn,\n",
    "                     schema=\"public\",\n",
    "                     if_exists=\"append\",   # structure already created\n",
    "                     index=False,\n",
    "                     dtype={\"geometry\": Geometry(\"POINT\",4326)})\n",
    "\n",
    "print(f\"Inserted {len(stops_gdf):,} stops\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdaf73d-ee6c-447a-9279-e8e84d253bd2",
   "metadata": {},
   "source": [
    "## 5. Load School Catchments\n",
    "### Merge Primary, Secondary, and Future Catchments\n",
    "* Reads each shapefile, renames `USE_ID → school_id` and `CATCH_TYPE → stage`,  \n",
    "  tags `sector='Government'`, concatenates.  \n",
    "* Recreates `public.schools` with a surrogate key (`gid SERIAL`) + GIST index,  \n",
    "  then inserts all polygons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca6d358-a457-4b5c-b369-fdf4dff85914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from geoalchemy2 import Geometry\n",
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "def read_catch(path):\n",
    "    gdf = gpd.read_file(path).to_crs(4326)\n",
    "    gdf = gdf.rename(columns={\n",
    "        \"USE_ID\": \"school_id\",\n",
    "        \"CATCH_TYPE\": \"stage\"\n",
    "    })\n",
    "    gdf[\"sector\"] = \"Government\"\n",
    "    return gdf[[\"school_id\", \"sector\", \"stage\", \"geometry\"]]\n",
    "\n",
    "# read each shapefile\n",
    "gdf_primary   = read_catch(\"data/catchments/catchments_primary.shp\")\n",
    "gdf_secondary = read_catch(\"data/catchments/catchments_secondary.shp\")\n",
    "gdf_future    = read_catch(\"data/catchments/catchments_future.shp\")\n",
    "\n",
    "schools = pd.concat([gdf_primary, gdf_secondary, gdf_future], ignore_index=True)\n",
    "\n",
    "schools.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f\"Total school polygons: {len(schools):,}\")\n",
    "\n",
    "# recreate spatial table with surrogate PK\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS public.schools;\n",
    "CREATE TABLE public.schools (\n",
    "    gid       SERIAL PRIMARY KEY,          -- surrogate key\n",
    "    school_id TEXT,\n",
    "    sector    TEXT,\n",
    "    stage     TEXT,\n",
    "    geometry  GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\n",
    "CREATE INDEX schools_geom_idx\n",
    "  ON public.schools USING GIST (geometry);\n",
    "\"\"\"))\n",
    "\n",
    "# insert rows\n",
    "schools.to_postgis(\"schools\", conn, schema=\"public\",\n",
    "                   if_exists=\"append\", index=False,\n",
    "                   dtype={\"geometry\": Geometry(\"MULTIPOLYGON\",4326)})\n",
    "\n",
    "print(\"School catchments loaded with surrogate primary key.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3149d3e-e5ea-4c2a-bce0-26074c0b10c8",
   "metadata": {},
   "source": [
    "## 6. Final Validation\n",
    "### Row Counts & SRID Check  \n",
    "* Row counts for all six tables (ensures data really loaded).  \n",
    "* SRID confirmation – every geometry table is EPSG 4326.  \n",
    "Both checks pass ⇒ Task 1 satisfied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c673e67-27d6-467a-a032-d21d001eb6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_sql(\"\"\"\n",
    "SELECT 'sa2_regions' AS table_name, COUNT(*) AS rows FROM public.sa2_regions\n",
    "UNION ALL\n",
    "SELECT 'stops',        COUNT(*) FROM public.stops\n",
    "UNION ALL\n",
    "SELECT 'schools',      COUNT(*) FROM public.schools\n",
    "UNION ALL\n",
    "SELECT 'businesses',   COUNT(*) FROM public.businesses\n",
    "UNION ALL\n",
    "SELECT 'population',   COUNT(*) FROM public.population\n",
    "UNION ALL\n",
    "SELECT 'income',       COUNT(*) FROM public.income;\n",
    "\"\"\", conn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7370ca-7c89-46c0-9dec-e8c9715ce921",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"\"\"\n",
    "SELECT f_table_name AS table_name, srid\n",
    "FROM   geometry_columns\n",
    "WHERE  f_table_schema = 'public';\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a281f-1dda-440a-9209-0b38f2d6b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# engine was returned by your pgconnect() call\n",
    "# replace `db` with whatever variable holds your SQLAlchemy engine\n",
    "print(\"engine    →\", db.engine.url)    \n",
    "print(\"conn      →\", conn.connection.get_dsn_parameters())\n",
    "\n",
    "# and run\n",
    "print(pd.read_sql(text(\"SELECT current_database()\"), db).iloc[0,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ddedab-8cfb-4bae-855e-c830a0d99dae",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "## Part 1\n",
    "Here are the function that returns all points of interests from the API within a specified bounding box of coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf4f471-0164-4997-9acb-60c2433ee9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_pois_from_api(minx, miny, maxx, maxy):\n",
    "    \n",
    "    url = \"https://maps.six.nsw.gov.au/arcgis/rest/services/public/NSW_POI/MapServer/0/query\"\n",
    "    \n",
    "    params = {\n",
    "        \"where\": \"1=1\",\n",
    "        \"geometry\": f\"{minx},{miny},{maxx},{maxy}\",\n",
    "        \"geometryType\": \"esriGeometryEnvelope\",\n",
    "        \"spatialRel\": \"esriSpatialRelIntersects\",\n",
    "        \"outFields\": \"*\",\n",
    "        \"returnGeometry\": \"true\",\n",
    "        \"f\": \"json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error fetching data:\", response.status_code)\n",
    "        return pd.DataFrame(), {}\n",
    "    \n",
    "    result = response.json()\n",
    "\n",
    "    if \"features\" not in result:\n",
    "        return pd.DataFrame(), result\n",
    "    \n",
    "    pois = []\n",
    "    \n",
    "    for feature in result[\"features\"]:\n",
    "        attr = feature[\"attributes\"]\n",
    "        geom = feature.get(\"geometry\", {})\n",
    "        \n",
    "        pois.append({\n",
    "            \"POIName\": attr.get(\"poiname\", None),\n",
    "            \"POIType\": attr.get(\"poitype\", None),\n",
    "            \"POIGroup\": attr.get(\"poigroup\", None),\n",
    "            \"POILabel\": attr.get(\"poilabel\", None),\n",
    "            \"POIAltLabel\": attr.get(\"poialtlabel\", None),\n",
    "            \"POILabelType\": attr.get(\"poilabeltype\", None),\n",
    "            \"Longitude\": geom.get(\"x\", None),\n",
    "            \"Latitude\": geom.get(\"y\", None)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(pois), result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97368d82-48d7-42cd-a02f-eb6abc5a97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_pois_from_api(minx, miny, maxx, maxy):\n",
    "    \n",
    "    url = \"https://maps.six.nsw.gov.au/arcgis/rest/services/public/NSW_POI/MapServer/0/query\"\n",
    "    \n",
    "    params = {\n",
    "        \"where\": \"1=1\",\n",
    "        \"geometry\": f\"{minx},{miny},{maxx},{maxy}\",\n",
    "        \"geometryType\": \"esriGeometryEnvelope\",\n",
    "        \"spatialRel\": \"esriSpatialRelIntersects\",\n",
    "        \"outFields\": \"*\",\n",
    "        \"returnGeometry\": \"true\",\n",
    "        \"f\": \"json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error fetching data:\", response.status_code)\n",
    "        return pd.DataFrame(), {}\n",
    "    \n",
    "    result = response.json()\n",
    "\n",
    "    if \"features\" not in result:\n",
    "        return pd.DataFrame(), result\n",
    "    \n",
    "    pois = []\n",
    "    \n",
    "    for feature in result[\"features\"]:\n",
    "        attr = feature[\"attributes\"]\n",
    "        geom = feature.get(\"geometry\", {})\n",
    "        \n",
    "        pois.append({\n",
    "            \"POIName\": attr.get(\"poiname\", None),\n",
    "            \"POIType\": attr.get(\"poitype\", None),\n",
    "            \"POIGroup\": attr.get(\"poigroup\", None),\n",
    "            \"POILabel\": attr.get(\"poilabel\", None),\n",
    "            \"POIAltLabel\": attr.get(\"poialtlabel\", None),\n",
    "            \"POILabelType\": attr.get(\"poilabeltype\", None),\n",
    "            \"Longitude\": geom.get(\"x\", None),\n",
    "            \"Latitude\": geom.get(\"y\", None)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(pois), result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a59a3-f58c-4754-9127-f1a9a0a30b3a",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "loop that cycles through each SA2 region within your selected SA4 region, waits a second before executing, then runs\n",
    "the function for that region’s bounding box, to find all points of interest within that SA2 region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98021bb-2eab-4472-9ae9-9477dfd6e7ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sqlalchemy import text, String, Integer, Float, DateTime\n",
    "\n",
    "selected_sa4 = [\"Sydney - Blacktown\", \"Sydney - Parramatta\", \"Sydney - Ryde\"]\n",
    "selected_sa4_str = \", \".join(f\"'{sa4}'\" for sa4 in selected_sa4)\n",
    "\n",
    "sa2_df = pd.read_sql(f\"\"\"\n",
    "SELECT sa2_code, sa2_name, sa4_name_2021, ST_Extent(geometry) AS bbox\n",
    "FROM public.sa2_regions\n",
    "WHERE sa4_name_2021 IN ({selected_sa4_str})\n",
    "GROUP BY sa2_code, sa2_name, sa4_name_2021\n",
    "\"\"\", conn)\n",
    "\n",
    "def bbox_parse(bbox_str):\n",
    "    bbox_str = bbox_str.replace(\"BOX(\", \"\").replace(\")\", \"\")\n",
    "    min_point, max_point = bbox_str.split(\",\")\n",
    "    minx, miny = map(float, min_point.strip().split(\" \"))\n",
    "    maxx, maxy = map(float, max_point.strip().split(\" \"))\n",
    "    return minx, miny, maxx, maxy\n",
    "\n",
    "sa2_df[[\"min_lon\", \"min_lat\", \"max_lon\", \"max_lat\"]] = sa2_df[\"bbox\"].apply(lambda x: pd.Series(bbox_parse(x)))\n",
    "\n",
    "results = []\n",
    "\n",
    "for index, row in sa2_df.iterrows():\n",
    "    sa2_code = row[\"sa2_code\"]\n",
    "    sa2_name = row[\"sa2_name\"]\n",
    "    min_lon = row[\"min_lon\"]\n",
    "    min_lat = row[\"min_lat\"]\n",
    "    max_lon = row[\"max_lon\"]\n",
    "    max_lat = row[\"max_lat\"]\n",
    "\n",
    "    print(f\"Fetching POIs for SA2: {sa2_name}\")\n",
    "\n",
    "    poi_df, result_p = get_pois_from_api(min_lon, min_lat, max_lon, max_lat)\n",
    "    # print(result_p)\n",
    "\n",
    "    if poi_df.empty:\n",
    "        continue\n",
    "\n",
    "    poi_df[\"SA2_CODE\"] = sa2_code\n",
    "    poi_df[\"SA2_NAME\"] = sa2_name\n",
    "    results.append(poi_df)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"Finished fetching POIs.\")\n",
    "\n",
    "if results:\n",
    "    final_poi_df = pd.concat(results, ignore_index=True)\n",
    "    print(f\"Total POIs fetched: {len(final_poi_df)}\")\n",
    "    display(final_poi_df.head())\n",
    "    \n",
    "\n",
    "    final_poi_df.to_sql(\"nsw_poi\", db, if_exists=\"replace\", index=False, dtype={\n",
    "        \"POIName\": String(),\n",
    "        \"POIType\": String(),\n",
    "        \"POIGroup\": Integer(),\n",
    "        \"POILabel\": String(),\n",
    "        \"POIAltLabel\": String(),\n",
    "        \"POILabelType\": String(),\n",
    "        \"Longitude\": Float(),\n",
    "        \"Latitude\": Float(),\n",
    "        \"SA2_CODE\": String(),\n",
    "        \"SA2_NAME\": String(),\n",
    "        \"timestamp\": String()   # → or DateTime() if you want timestamp\n",
    "    })\n",
    "\n",
    "    print(\"POIs successfully inserted into table 'nsw_poi'.\")\n",
    "else:\n",
    "    print(\"No POIs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e51f63-46e0-45e2-9492-f685273f4586",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f8dfa-5ac2-4269-b282-c27ce4693463",
   "metadata": {},
   "source": [
    "## Businesses \n",
    "We focus on industries that directly provide everyday goods, services, and amenities to local residents.  To that end, we exclude:\n",
    "\t\n",
    "    •\tHeavy-industry & utilities (Mining, Manufacturing, Agriculture, Electricity/Gas/Water/Waste, Construction)\n",
    "These sectors typically locate outside dense population centers and don’t reflect the local availability of shops, clinics, or leisure services.\n",
    "\t\n",
    "    •\tPublic Administration & Safety\n",
    "Although essential, these are government-run functions rather than private-sector businesses, and so are better handled by dedicated public-sector layers.\n",
    "\t\n",
    "    •\tAdministrative & Support Services\n",
    "Roles like cleaning, security or back-office operations don’t signal consumer-facing amenities; they rarely indicate local resource richness from a resident’s perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5786fbd4-9aa5-45b0-b737-0693802fd957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "sql = text(\"\"\"\n",
    "DROP TABLE IF EXISTS public.sa2_summary;\n",
    "\n",
    "CREATE TABLE public.sa2_summary AS\n",
    "SELECT\n",
    "  sr.sa2_code,\n",
    "  sr.sa2_name,\n",
    "  SUM(b.total_businesses)\n",
    "    / (pop.total_people   / 1000.0) AS business_count\n",
    "FROM businesses b\n",
    "  JOIN sa2_regions    sr  USING (sa2_name)\n",
    "  JOIN population pop USING (sa2_name)\n",
    "WHERE sr.sa4_name_2021 IN (\n",
    "    'Sydney - Blacktown',\n",
    "    'Sydney - Parramatta',\n",
    "    'Sydney - Ryde'\n",
    "  )\n",
    "  AND b.industry_name IN (\n",
    "    'Health Care and Social Assistance',\n",
    "    'Education and Training',\n",
    "    'Retail Trade',\n",
    "    'Accommodation and Food Services',\n",
    "    'Transport, Postal and Warehousing',\n",
    "    'Financial and Insurance Services',\n",
    "    'Professional, Scientific and Technical Services',\n",
    "    'Arts and Recreation Services',\n",
    "    'Rental, Hiring and Real Estate Services'\n",
    "  )\n",
    "  AND total_people >= 100\n",
    "GROUP BY\n",
    "  sr.sa2_code,\n",
    "  sr.sa2_name,\n",
    "  pop.total_people\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(sql)\n",
    "\n",
    "\n",
    "summary_df = query(conn, \"SELECT * FROM public.sa2_summary;\")\n",
    "print(summary_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe246ac-7fb5-4e33-a7d5-595cfa57a9e7",
   "metadata": {},
   "source": [
    "## Stops\n",
    "We capture public‐transport accessibility by counting how many transit stops lie within each SA2.  A higher stops_count indicates better local connectivity and ease of movement for residents.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98849d0d-365e-4ca9-b8e3-32934964963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = text(\"\"\"\n",
    "-- 1) Add the new column if it doesn't already exist\n",
    "ALTER TABLE public.sa2_summary\n",
    "ADD COLUMN IF NOT EXISTS stops_count INTEGER;\n",
    "\n",
    "-- 2) Update that column by counting stops per SA2\n",
    "UPDATE public.sa2_summary AS summ\n",
    "SET stops_count = sub.stops_count\n",
    "FROM (\n",
    "  SELECT\n",
    "    sr.sa2_name,\n",
    "    COUNT(*) AS stops_count\n",
    "  FROM sa2_regions AS sr\n",
    "  JOIN stops AS s\n",
    "    ON ST_Contains(sr.geometry, s.geometry)\n",
    "  WHERE\n",
    "    sr.sa4_name_2021 IN (\n",
    "      'Sydney - Blacktown',\n",
    "      'Sydney - Parramatta',\n",
    "      'Sydney - Ryde'\n",
    "    )\n",
    "  GROUP BY\n",
    "    sr.sa2_name\n",
    ") AS sub\n",
    "WHERE summ.sa2_name = sub.sa2_name;\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(sql)\n",
    "\n",
    "summary_df = query(\n",
    "    conn,\n",
    "    \"SELECT * FROM public.sa2_summary;\"\n",
    ")\n",
    "print(summary_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d585b3a6-097f-4827-8ee1-b671a54b6db7",
   "metadata": {},
   "source": [
    "## Schools\n",
    "To gauge local education access, we count how many distinct school‐catchment polygons actually overlap each SA2, then express that as “catchments per 1 000 young people.”  We:\n",
    "\t\n",
    "    •\tExclude any SA2 with fewer than 100 residents aged 0–19, to avoid unstable rates.\n",
    "\t•\tDivide the raw catchment count by (young_pop / 1 000) so that areas with very few kids don’t produce huge per-capita spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bff81a-badb-480c-98d1-33611b93119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = text(\"\"\"\n",
    "-- 1) Add the new column if it doesn't already exist\n",
    "ALTER TABLE public.sa2_summary\n",
    "ADD COLUMN IF NOT EXISTS catchments_count DOUBLE PRECISION;\n",
    "\n",
    "-- 2) Update that column by computing catchments per 1 000 young people\n",
    "WITH pop_young AS (\n",
    "  SELECT\n",
    "    sa2_name,\n",
    "    (\n",
    "      \"0-4_people\"\n",
    "    + \"5-9_people\"\n",
    "    + \"10-14_people\"\n",
    "    + \"15-19_people\"\n",
    "    ) AS young_pop\n",
    "  FROM population\n",
    ")\n",
    "UPDATE public.sa2_summary AS summ\n",
    "SET catchments_count = sub.catchments_count\n",
    "FROM (\n",
    "  SELECT\n",
    "    sr.sa2_name,\n",
    "    COUNT(*)::float\n",
    "      / (pyoung.young_pop / 1000.0) AS catchments_count\n",
    "  FROM schools      AS s\n",
    "  JOIN sa2_regions AS sr\n",
    "    ON  ST_Intersects(sr.geometry, s.geometry)\n",
    "    AND NOT ST_Touches(   sr.geometry, s.geometry)\n",
    "  JOIN pop_young   AS pyoung\n",
    "    ON pyoung.sa2_name = sr.sa2_name\n",
    "  WHERE\n",
    "    sr.sa4_name_2021 IN (\n",
    "      'Sydney - Blacktown',\n",
    "      'Sydney - Parramatta',\n",
    "      'Sydney - Ryde'\n",
    "    )\n",
    "    AND pyoung.young_pop >= 100\n",
    "  GROUP BY\n",
    "    sr.sa2_name,\n",
    "    pyoung.young_pop\n",
    ") AS sub\n",
    "WHERE summ.sa2_name = sub.sa2_name;\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(sql)\n",
    "\n",
    "summary_df = query(\n",
    "    conn,\n",
    "    \"SELECT * FROM public.sa2_summary;\"\n",
    ")\n",
    "print(summary_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3896cbfd-050a-429e-a915-05102fcaafce",
   "metadata": {},
   "source": [
    "## NSW POI\n",
    "To measure local amenity density, we count only those points of interest that represent community-facing services and everyday resources.  We exclude:\n",
    "\t\n",
    "    •\tIndustrial or utility facilities (Filtration Plant, Sewage Works, Pumping Station) as they don’t serve residents directly.\n",
    "\t•\tLarge‐scale commercial or tourism sites (Tourist Park, Silo – Commercial, Quarry – Open Cut) which typically lie outside residential cores.\n",
    "\t•\tVery broad or redundant places (City, Suburb, Locality) that don’t convey true amenity density.\n",
    "\t•\tNiche or infrequent-use sites (Motor Racing Track, Helipad, Gaol) which aren’t regular community resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd02e2-542f-4dda-ade7-28e0a5dcf971",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = text(\"\"\"\n",
    "-- 1) Add the new column if it doesn't already exist\n",
    "ALTER TABLE public.sa2_summary\n",
    "ADD COLUMN IF NOT EXISTS poi_count INTEGER;\n",
    "\n",
    "-- 2) Update that column by counting POIs per SA2\n",
    "UPDATE public.sa2_summary AS summ\n",
    "SET poi_count = sub.poi_count\n",
    "FROM (\n",
    "  SELECT\n",
    "    sr.sa2_name,\n",
    "    COUNT(*) AS poi_count\n",
    "  FROM nsw_poi AS n\n",
    "  JOIN sa2_regions AS sr\n",
    "    ON sr.sa2_name = n.\"SA2_NAME\"\n",
    "  WHERE\n",
    "    sr.sa4_name_2021 IN (\n",
    "      'Sydney - Blacktown',\n",
    "      'Sydney - Parramatta',\n",
    "      'Sydney - Ryde'\n",
    "    )\n",
    "    AND n.\"POIType\" IN (\n",
    "      'Library',\n",
    "      'Park',\n",
    "      'Community Facility',\n",
    "      'Child Care Centre',\n",
    "      'Primary School',\n",
    "      'High School',\n",
    "      'General Hospital',\n",
    "      'Community Medical Centre',\n",
    "      'Transport Interchange',\n",
    "      'Post Office',\n",
    "      'Sports Centre / Sports Field',\n",
    "      'Art Gallery / Museum'\n",
    "    )\n",
    "  GROUP BY\n",
    "    sr.sa2_name\n",
    ") AS sub\n",
    "WHERE summ.sa2_name = sub.sa2_name;\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(sql)\n",
    "\n",
    "summary_df = query(\n",
    "    conn,\n",
    "    \"SELECT * FROM public.sa2_summary;\"\n",
    ")\n",
    "print(summary_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff5dea8-ac02-4aa1-b3d6-17f182b8214b",
   "metadata": {},
   "source": [
    "## Z scores and Final Sigmoid Score\n",
    "To bring all four metrics (business, stops, schools, POIs) onto a common scale and combine them into one index, we:\n",
    "\t\n",
    "    • Standardize each metric by converting raw counts into z-scores, where mu and sigma are the mean and population standard deviation of that metric across your selected SA2s.\n",
    "\t\n",
    "    • Sum the four z-scores into a single value, so positive values indicate above-average resource levels and negatives indicate below-average.\n",
    "\t\n",
    "    • Apply a sigmoid transform, to squash the combined score into the (0,1) range, making it easy to interpret (closer to 1 → very well-resourced; closer to 0 → poorly-resourced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e89ecf-1804-4b29-80a8-0c585a7bbc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = text(\"\"\"\n",
    "ALTER TABLE public.sa2_summary\n",
    "  ADD COLUMN IF NOT EXISTS z_business          DOUBLE PRECISION,\n",
    "  ADD COLUMN IF NOT EXISTS z_stops             DOUBLE PRECISION,\n",
    "  ADD COLUMN IF NOT EXISTS z_schools           DOUBLE PRECISION,\n",
    "  ADD COLUMN IF NOT EXISTS z_poi               DOUBLE PRECISION,\n",
    "  ADD COLUMN IF NOT EXISTS z_total             DOUBLE PRECISION,\n",
    "  ADD COLUMN IF NOT EXISTS well_resourced_score DOUBLE PRECISION;\n",
    "\n",
    "WITH stats AS (\n",
    "  SELECT\n",
    "    AVG(business_count)      AS mean_bc,\n",
    "    STDDEV_POP(business_count) AS sd_bc,\n",
    "    AVG(stops_count)         AS mean_sc,\n",
    "    STDDEV_POP(stops_count)    AS sd_sc,\n",
    "    AVG(catchments_count)    AS mean_cc,\n",
    "    STDDEV_POP(catchments_count) AS sd_cc,\n",
    "    AVG(poi_count)           AS mean_pc,\n",
    "    STDDEV_POP(poi_count)      AS sd_pc\n",
    "  FROM public.sa2_summary\n",
    ")\n",
    "UPDATE public.sa2_summary\n",
    "SET\n",
    "  z_business = (business_count - stats.mean_bc) / NULLIF(stats.sd_bc,0),\n",
    "  z_stops    = (stops_count    - stats.mean_sc) / NULLIF(stats.sd_sc,0),\n",
    "  z_schools  = (catchments_count - stats.mean_cc) / NULLIF(stats.sd_cc,0),\n",
    "  z_poi      = (poi_count      - stats.mean_pc) / NULLIF(stats.sd_pc,0),\n",
    "  z_total    = (\n",
    "      (business_count   - stats.mean_bc) / NULLIF(stats.sd_bc,0)\n",
    "    + (stops_count      - stats.mean_sc) / NULLIF(stats.sd_sc,0)\n",
    "    + (catchments_count - stats.mean_cc) / NULLIF(stats.sd_cc,0)\n",
    "    + (poi_count        - stats.mean_pc) / NULLIF(stats.sd_pc,0)\n",
    "  ),\n",
    "  well_resourced_score = 1.0 / (1.0 + EXP(-(\n",
    "      (business_count   - stats.mean_bc) / NULLIF(stats.sd_bc,0)\n",
    "    + (stops_count      - stats.mean_sc) / NULLIF(stats.sd_sc,0)\n",
    "    + (catchments_count - stats.mean_cc) / NULLIF(stats.sd_cc,0)\n",
    "    + (poi_count        - stats.mean_pc) / NULLIF(stats.sd_pc,0)\n",
    "  )))\n",
    "FROM stats;\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(sql)\n",
    "\n",
    "summary_df = query(\n",
    "    conn,\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "      sa2_code, \n",
    "      sa2_name, \n",
    "      z_business, \n",
    "      z_stops, \n",
    "      z_schools, \n",
    "      z_poi, \n",
    "      z_total, \n",
    "      well_resourced_score\n",
    "    FROM public.sa2_summary\n",
    "    \"\"\"\n",
    ")\n",
    "print(summary_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab491207-bcc8-4a45-9bcb-8a134d5ea80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from sqlalchemy import text\n",
    "\n",
    "# 1) Load SA2 scores and incomes into a DataFrame\n",
    "summary_df_raw = query(\n",
    "    conn,\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "      s.sa2_name,\n",
    "      r.sa4_name_2021,\n",
    "      s.well_resourced_score,\n",
    "      i.median_income\n",
    "    FROM sa2_summary AS s\n",
    "    JOIN income       AS i USING (sa2_name)\n",
    "    JOIN sa2_regions  AS r USING (sa2_name)\n",
    "    \"\"\"\n",
    ")\n",
    "print(f\"Rows fetched from SQL: {len(summary_df_raw)}\")\n",
    "\n",
    "# Handle potential non-string median_income before .str.replace\n",
    "summary_df = summary_df_raw.copy() # Work on a copy\n",
    "summary_df[\"median_income\"] = summary_df[\"median_income\"].astype(str).str.replace(\",\", \"\")\n",
    "summary_df[\"median_income\"] = pd.to_numeric(\n",
    "    summary_df[\"median_income\"],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "print(f\"Rows after median_income numeric conversion: {len(summary_df)}\")\n",
    "print(f\"NaNs in median_income after coercion: {summary_df['median_income'].isna().sum()}\")\n",
    "print(f\"NaNs in well_resourced_score: {summary_df['well_resourced_score'].isna().sum()}\")\n",
    "\n",
    "# 3) Overall Pearson correlation across all 67 SA2 regions\n",
    "r_overall, p_overall = pearsonr(\n",
    "    summary_df[\"well_resourced_score\"],\n",
    "    summary_df[\"median_income\"]\n",
    ")\n",
    "print(f\"Overall (n={len(summary_df)}): Pearson r = {r_overall:.3f}, p = {p_overall:.3f}\")\n",
    "\n",
    "# 4) Pearson correlation within each SA4 region\n",
    "regions = [\"Sydney - Blacktown\", \"Sydney - Parramatta\", \"Sydney - Ryde\"]\n",
    "for region in regions:\n",
    "    sub = summary_df[summary_df[\"sa4_name_2021\"] == region]\n",
    "    r, p = pearsonr(sub[\"well_resourced_score\"], sub[\"median_income\"])\n",
    "    print(f\"{region} (n={len(sub)}): Pearson r = {r:.3f}, p = {p:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04159de-98d3-40c9-bbd7-c878cf9bdee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# 1) Load SA2 data with z-scores and incomes\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  s.sa2_name,\n",
    "  r.sa4_name_2021,\n",
    "  s.well_resourced_score,\n",
    "  s.z_business,\n",
    "  s.z_stops,\n",
    "  s.z_schools,\n",
    "  s.z_poi,\n",
    "  i.median_income\n",
    "FROM sa2_summary AS s\n",
    "JOIN income     AS i USING (sa2_name)\n",
    "JOIN sa2_regions AS r USING (sa2_name)\n",
    "\"\"\"\n",
    "df = query(conn, sql).dropna()\n",
    "\n",
    "# 2) Clean median_income and convert to float\n",
    "df[\"median_income\"] = df[\"median_income\"].str.replace(\",\", \"\")\n",
    "df[\"median_income\"] = pd.to_numeric(df[\"median_income\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"well_resourced_score\", \"median_income\"])\n",
    "\n",
    "# List of component columns and the composite\n",
    "components    = [\"z_business\", \"z_stops\", \"z_schools\", \"z_poi\"]\n",
    "composite_col = \"well_resourced_score\"\n",
    "\n",
    "# 3.1 Direct influence: Pearson r of each component vs composite\n",
    "print(\"1) Direct Pearson correlations with final score:\")\n",
    "for comp in components:\n",
    "    r, p = pearsonr(df[comp], df[composite_col])\n",
    "    print(f\"   {comp:>12s} → r = {r:.3f}, p = {p:.3f}\")\n",
    "\n",
    "# 3.2 Leave-one-out rank stability: drop each component, re-rank, then Spearman rho\n",
    "orig_rank = df[composite_col].rank(method=\"average\")\n",
    "print(\"\\n2) Leave-one-out Spearman rank correlations:\")\n",
    "for comp in components:\n",
    "    others   = [c for c in components if c != comp]\n",
    "    raw_sum  = df[others].sum(axis=1)\n",
    "    mod_score = 1 / (1 + np.exp(-raw_sum))  # reapply sigmoid if used originally\n",
    "    mod_rank  = mod_score.rank(method=\"average\")\n",
    "    rho, p    = spearmanr(orig_rank, mod_rank)\n",
    "    print(f\"   without {comp:>8s} → ρ = {rho:.3f}, p = {p:.3f}\")\n",
    "\n",
    "# 3.3 Distribution shifts: compare mean, median, std of drop-one composites vs original\n",
    "orig_stats = (\n",
    "    df[composite_col].mean(),\n",
    "    df[composite_col].median(),\n",
    "    df[composite_col].std()\n",
    ")\n",
    "print(\"\\n3) Distribution statistics comparison (mean, median, std):\")\n",
    "print(f\"   original       : mean = {orig_stats[0]:.3f}, median = {orig_stats[1]:.3f}, std = {orig_stats[2]:.3f}\")\n",
    "for comp in components:\n",
    "    others    = [c for c in components if c != comp]\n",
    "    raw_sum   = df[others].sum(axis=1)\n",
    "    mod_score = 1 / (1 + np.exp(-raw_sum))\n",
    "    stats     = (mod_score.mean(), np.median(mod_score), mod_score.std())\n",
    "    print(f\"   without {comp:>8s} : mean = {stats[0]:.3f}, median = {stats[1]:.3f}, std = {stats[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe6ba5-0a53-4dec-b089-9f9690651ea2",
   "metadata": {},
   "source": [
    "### 1. Score Distribution\n",
    "**Purpose:**  \n",
    "Shows how well-resourced scores are distributed across all SA2 regions in your selected zones.\n",
    "\n",
    "**Key Insights:**\n",
    "- Reveals whether scores cluster around certain values (e.g., mostly average) or span the full range (0–1).\n",
    "- The boxplot compares score distributions between your three SA4 zones, highlighting any systematic differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365cf0bc-6257-4016-bc4e-42acd966d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Get the scores data with qualified column names\n",
    "scores_df = pd.read_sql(text(\"\"\"\n",
    "    SELECT \n",
    "        public.sa2_summary.sa2_name,  -- Specify which table's sa2_name to use\n",
    "        well_resourced_score, \n",
    "        sa4_name_2021 \n",
    "    FROM public.sa2_summary \n",
    "    JOIN public.sa2_regions USING (sa2_code)\n",
    "\"\"\"), conn)\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histogram of scores\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(scores_df['well_resourced_score'], bins=15, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Well-Resourced Scores')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Number of SA2 Regions')\n",
    "\n",
    "\n",
    "# Boxplot by SA4 zone - updated to avoid deprecation warning\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(data=scores_df, x='sa4_name_2021', y='well_resourced_score', \n",
    "            hue='sa4_name_2021', palette='pastel')\n",
    "plt.title('Score Distribution by SA4 Zone')\n",
    "plt.xlabel('SA4 Zone')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70584619-866d-41df-a8d3-9dd6658e660b",
   "metadata": {},
   "source": [
    "### 2. Choropleth Map\n",
    "**Purpose:**  \n",
    "Displays geographic patterns in well-resourced scores across your selected regions.\n",
    "\n",
    "**Key Insights:**\n",
    "- Identifies spatial clusters of high/low scores (e.g., city centers vs. suburbs).\n",
    "- SA4 boundaries provide context for regional disparities.\n",
    "- Color gradient (red–yellow–green) intuitively shows performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c213c68-f8bb-4b94-be87-c3da668e05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install contextily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc51e9-b690-4513-9e4f-04271acafdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "\n",
    "# Get the spatial data with scores\n",
    "map_df = gpd.read_postgis(text(\"\"\"\n",
    "    SELECT \n",
    "        sr.sa2_code,\n",
    "        sr.sa2_name,\n",
    "        sr.geometry,\n",
    "        ss.well_resourced_score,\n",
    "        sr.sa4_name_2021\n",
    "    FROM public.sa2_regions sr\n",
    "    JOIN public.sa2_summary ss ON sr.sa2_code = ss.sa2_code\n",
    "    WHERE sr.sa4_name_2021 IN ('Sydney - Blacktown', 'Sydney - Parramatta', 'Sydney - Ryde')\n",
    "\"\"\"), conn, geom_col='geometry')\n",
    "\n",
    "# Plot the map\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Plot the choropleth\n",
    "map_df.plot(column='well_resourced_score', \n",
    "            ax=ax, \n",
    "            legend=True,\n",
    "            legend_kwds={'label': \"Well-Resourced Score\", 'shrink': 0.5},\n",
    "            cmap='RdYlGn',  # Red-Yellow-Green color scale\n",
    "            edgecolor='black',\n",
    "            linewidth=0.3,\n",
    "            missing_kwds={'color': 'lightgrey'})\n",
    "\n",
    "# Add SA4 boundaries for context\n",
    "sa4_boundaries = gpd.read_postgis(text(\"\"\"\n",
    "    SELECT \n",
    "        sa4_name_2021,\n",
    "        ST_Union(geometry) as geometry\n",
    "    FROM public.sa2_regions\n",
    "    WHERE sa4_name_2021 IN ('Sydney - Blacktown', 'Sydney - Parramatta', 'Sydney - Ryde')\n",
    "    GROUP BY sa4_name_2021\n",
    "\"\"\"), conn, geom_col='geometry')\n",
    "\n",
    "sa4_boundaries.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Add labels for SA4 zones\n",
    "for idx, row in sa4_boundaries.iterrows():\n",
    "    ax.annotate(text=row['sa4_name_2021'], \n",
    "                xy=row['geometry'].centroid.coords[0],\n",
    "                ha='center', \n",
    "                fontsize=10,\n",
    "                bbox=dict(boxstyle=\"round\", facecolor='white', alpha=0.7))\n",
    "\n",
    "# Add basemap\n",
    "ctx.add_basemap(ax, crs=map_df.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n",
    "\n",
    "plt.title('Well-Resourced Scores by SA2 Region')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd0fd3-d011-4a11-918a-54baf9afd416",
   "metadata": {},
   "source": [
    "### 3. Income Correlation\n",
    "**Purpose:**  \n",
    "Tests whether wealthier areas tend to be better resourced.\n",
    "\n",
    "**Key Insights:**\n",
    "- Positive correlation suggests resources align with income levels.\n",
    "- Weak/no correlation implies your score captures independent factors.\n",
    "- Outliers (high-score/low-income or vice versa) may reveal interesting exceptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f935651-f038-4867-8bb0-6517046d42aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7fbc03-e4d2-4932-8c35-e50e40f2024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data with income - fixed type mismatch and convert data types\n",
    "corr_df = pd.read_sql(text(\"\"\"\n",
    "    SELECT \n",
    "        ss.sa2_name,\n",
    "        ss.well_resourced_score,\n",
    "        i.median_income,\n",
    "        sr.sa4_name_2021\n",
    "    FROM public.sa2_summary ss\n",
    "    JOIN public.income i ON ss.sa2_code::text = i.sa2_code21::text\n",
    "    JOIN public.sa2_regions sr ON ss.sa2_code = sr.sa2_code\n",
    "\"\"\"), conn)\n",
    "\n",
    "# Convert columns to numeric types\n",
    "corr_df['well_resourced_score'] = pd.to_numeric(corr_df['well_resourced_score'], errors='coerce')\n",
    "corr_df['median_income'] = pd.to_numeric(corr_df['median_income'], errors='coerce')\n",
    "\n",
    "# Drop any rows with missing values after conversion\n",
    "corr_df = corr_df.dropna(subset=['well_resourced_score', 'median_income'])\n",
    "\n",
    "# Now create the plot with the properly formatted data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(data=corr_df, \n",
    "            x='well_resourced_score', \n",
    "            y='median_income',\n",
    "            scatter_kws={'alpha': 0.6},\n",
    "            line_kws={'color': 'red'})\n",
    "\n",
    "plt.title('Well-Resourced Score vs Median Income')\n",
    "plt.xlabel('Well-Resourced Score')\n",
    "plt.ylabel('Median Income ($)')\n",
    "plt.grid(True)\n",
    "\n",
    "# Calculate correlation coefficient\n",
    "correlation = corr_df['well_resourced_score'].corr(corr_df['median_income'])\n",
    "plt.annotate(f'Correlation: {correlation:.2f}', \n",
    "             xy=(0.05, 0.95), \n",
    "             xycoords='axes fraction',\n",
    "             bbox=dict(boxstyle=\"round\", facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.show()\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0703234-49cd-4cbe-8a65-b03236da5ab0",
   "metadata": {},
   "source": [
    "### 4. Component Analysis\n",
    "**Purpose:**  \n",
    "Breaks down which factors (businesses, stops, schools, POIs) most influence scores.\n",
    "\n",
    "**Key Insights:**\n",
    "- Shows which components vary most (wide box = big differences between regions).\n",
    "- Components above/below the zero line indicate strengths/weaknesses overall.\n",
    "- Helps diagnose whether certain resources are consistently scarce.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94382ce-f376-4ee5-aaed-8f3355ff5336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the z-scores data\n",
    "components_df = pd.read_sql(text(\"\"\"\n",
    "    SELECT \n",
    "        sa2_name,\n",
    "        z_business,\n",
    "        z_stops,\n",
    "        z_schools,\n",
    "        z_poi,\n",
    "        well_resourced_score\n",
    "    FROM public.sa2_summary\n",
    "    ORDER BY well_resourced_score DESC\n",
    "\"\"\"), conn)\n",
    "\n",
    "# Melt the dataframe for easier plotting\n",
    "melted_df = pd.melt(components_df, \n",
    "                    id_vars=['sa2_name', 'well_resourced_score'], \n",
    "                    value_vars=['z_business', 'z_stops', 'z_schools', 'z_poi'],\n",
    "                    var_name='Component', \n",
    "                    value_name='Z-Score')\n",
    "\n",
    "# Create more readable component names\n",
    "component_names = {\n",
    "    'z_business': 'Businesses',\n",
    "    'z_stops': 'Transit Stops',\n",
    "    'z_schools': 'Schools',\n",
    "    'z_poi': 'Points of Interest'\n",
    "}\n",
    "melted_df['Component'] = melted_df['Component'].map(component_names)\n",
    "\n",
    "# Plot the component contributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=melted_df, x='Component', y='Z-Score', palette='Set2', hue='Component')\n",
    "plt.title('Distribution of Z-Scores by Component', fontsize=14)\n",
    "plt.xlabel('Component', fontsize=12)\n",
    "plt.ylabel('Z-Score', fontsize=12)\n",
    "\n",
    "# Add reference line at 0\n",
    "plt.axhline(0, color='gray', linestyle='--', alpha=0.7, label='Zero Reference')\n",
    "\n",
    "# Add a bit more context with grid\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Add some statistics text\n",
    "for i, comp in enumerate(component_names.values()):\n",
    "    subset = melted_df[melted_df['Component'] == comp]['Z-Score']\n",
    "    median = subset.median()\n",
    "    plt.annotate(f'Median: {median:.2f}', \n",
    "                 xy=(i, subset.min() - 0.2), \n",
    "                 ha='center',\n",
    "                 fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ce06f5-ff10-43b9-b87d-de617e5c1815",
   "metadata": {},
   "source": [
    "### 5. Top/Bottom Performers\n",
    "**Purpose:**  \n",
    "Highlights the highest and lowest scoring regions by name.\n",
    "\n",
    "**Key Insights:**\n",
    "- Reveals specific areas to examine as success stories or priorities for improvement.\n",
    "- Large gaps between top and bottom indicate inequality in resource distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66032562-823d-4003-848f-8b76315cf1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top and bottom 5 regions\n",
    "top_5 = components_df.nlargest(5, 'well_resourced_score')\n",
    "bottom_5 = components_df.nsmallest(5, 'well_resourced_score')\n",
    "\n",
    "# Add a category column to distinguish top from bottom\n",
    "top_5['category'] = 'Top 5'\n",
    "bottom_5['category'] = 'Bottom 5'\n",
    "top_bottom_df = pd.concat([top_5, bottom_5])\n",
    "\n",
    "# Sort the combined dataframe for better visual ordering\n",
    "top_bottom_df = top_bottom_df.sort_values('well_resourced_score')\n",
    "\n",
    "# Plot the scores with enhanced styling\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(data=top_bottom_df, \n",
    "                x='well_resourced_score', \n",
    "                y='sa2_name',\n",
    "                hue='category',  # Color bars based on top/bottom category\n",
    "                palette={'Top 5': 'forestgreen', 'Bottom 5': 'firebrick'},\n",
    "                dodge=False)  # Don't dodge the bars\n",
    "\n",
    "# Add the score values as text at the end of each bar\n",
    "for i, v in enumerate(top_bottom_df['well_resourced_score']):\n",
    "    ax.text(v + 0.01, i, f'{v:.2f}', va='center')\n",
    "\n",
    "plt.title('Top and Bottom 5 Performing SA2 Regions', fontsize=14)\n",
    "plt.xlabel('Well-Resourced Score', fontsize=12)\n",
    "plt.ylabel('SA2 Region', fontsize=12)\n",
    "plt.xlim(0, max(top_bottom_df['well_resourced_score']) * 1.1)  # Dynamic limit with space for text\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add a legend in a good position\n",
    "plt.legend(title='', loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbc4459-e09d-424e-bc99-41c85b69ed45",
   "metadata": {},
   "source": [
    "### 6. Interactive Map (Optional)\n",
    "**Purpose:**  \n",
    "Allows readers to explore scores at their own pace.\n",
    "\n",
    "**Key Features:**\n",
    "- Hover tooltips show exact scores and region names.\n",
    "- Zoom/pan functionality enables neighborhood-level inspection.\n",
    "- Useful for digital reports or presentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58e78b-5908-4ef2-a204-3d5059447333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a47d35a-53c8-43b8-ae2b-dabaf8749fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster, FeatureGroupSubGroup\n",
    "import numpy as np\n",
    "\n",
    "# Create a base map centered on your regions\n",
    "m = folium.Map(location=[-33.8, 151.0], zoom_start=11, tiles='cartodbpositron')\n",
    "\n",
    "# Add multiple base tile layers\n",
    "folium.TileLayer('cartodbpositron', name='Light Map').add_to(m)\n",
    "folium.TileLayer('cartodbdark_matter', name='Dark Map').add_to(m)\n",
    "folium.TileLayer('OpenStreetMap', name='OpenStreetMap').add_to(m)\n",
    "folium.TileLayer('Stamen Terrain', name='Terrain').add_to(m)\n",
    "\n",
    "# Create a custom colormap function\n",
    "def get_color(score):\n",
    "    if score is None:\n",
    "        return '#CCCCCC'  # Gray for missing data\n",
    "    elif score >= 0.8:\n",
    "        return '#1a9850'  # Dark green\n",
    "    elif score >= 0.6:\n",
    "        return '#91cf60'  # Light green\n",
    "    elif score >= 0.4:\n",
    "        return '#ffffbf'  # Yellow\n",
    "    elif score >= 0.2:\n",
    "        return '#fc8d59'  # Orange\n",
    "    else:\n",
    "        return '#d73027'  # Red\n",
    "\n",
    "# Style function for regions\n",
    "def style_function(feature):\n",
    "    score = feature['properties']['well_resourced_score']\n",
    "    return {\n",
    "        'fillColor': get_color(score),\n",
    "        'color': 'black',\n",
    "        'weight': 1,\n",
    "        'fillOpacity': 0.7\n",
    "    }\n",
    "\n",
    "# Highlight function for hover effect\n",
    "def highlight_function(feature):\n",
    "    return {\n",
    "        'weight': 3,\n",
    "        'color': '#666',\n",
    "        'dashArray': '',\n",
    "        'fillOpacity': 0.9\n",
    "    }\n",
    "\n",
    "# Add choropleth layer with custom styling\n",
    "choropleth = folium.GeoJson(\n",
    "    map_df,\n",
    "    name='Well-Resourced Scores',\n",
    "    style_function=style_function,\n",
    "    highlight_function=highlight_function,\n",
    "    tooltip=folium.GeoJsonTooltip(\n",
    "        fields=['sa2_name', 'well_resourced_score', 'sa4_name_2021'],\n",
    "        aliases=['Area:', 'Score:', 'Region:'],\n",
    "        localize=True,\n",
    "        sticky=True,\n",
    "        labels=True,\n",
    "        style=\"\"\"\n",
    "            background-color: #F0EFEF;\n",
    "            border: 2px solid black;\n",
    "            border-radius: 3px;\n",
    "            box-shadow: 3px 3px 3px rgba(0,0,0,0.4);\n",
    "            font-size: 14px;\n",
    "            padding: 10px;\n",
    "        \"\"\"\n",
    "    )\n",
    ").add_to(m)\n",
    "\n",
    "# Add a legend\n",
    "legend_html = '''\n",
    "    <div style=\"position: fixed; \n",
    "        bottom: 50px; right: 50px; width: 180px; height: 170px; \n",
    "        border:2px solid grey; z-index:9999; font-size:14px;\n",
    "        background-color: white; padding: 10px; border-radius: 5px\">\n",
    "    <p style=\"margin-top: 0; margin-bottom: 5px;\"><b>Well-Resourced Score</b></p>\n",
    "    <div style=\"display: flex; align-items: center; margin-bottom: 5px;\">\n",
    "        <span style=\"background-color:#1a9850; width:20px; height:20px; display:inline-block; margin-right:5px;\"></span>\n",
    "        <span>0.8 - 1.0</span>\n",
    "    </div>\n",
    "    <div style=\"display: flex; align-items: center; margin-bottom: 5px;\">\n",
    "        <span style=\"background-color:#91cf60; width:20px; height:20px; display:inline-block; margin-right:5px;\"></span>\n",
    "        <span>0.6 - 0.8</span>\n",
    "    </div>\n",
    "    <div style=\"display: flex; align-items: center; margin-bottom: 5px;\">\n",
    "        <span style=\"background-color:#ffffbf; width:20px; height:20px; display:inline-block; margin-right:5px;\"></span>\n",
    "        <span>0.4 - 0.6</span>\n",
    "    </div>\n",
    "    <div style=\"display: flex; align-items: center; margin-bottom: 5px;\">\n",
    "        <span style=\"background-color:#fc8d59; width:20px; height:20px; display:inline-block; margin-right:5px;\"></span>\n",
    "        <span>0.2 - 0.4</span>\n",
    "    </div>\n",
    "    <div style=\"display: flex; align-items: center; margin-bottom: 5px;\">\n",
    "        <span style=\"background-color:#d73027; width:20px; height:20px; display:inline-block; margin-right:5px;\"></span>\n",
    "        <span>0.0 - 0.2</span>\n",
    "    </div>\n",
    "    </div>\n",
    "'''\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# Create a marker cluster group for top regions\n",
    "marker_cluster = MarkerCluster(name=\"Top Regions\").add_to(m)\n",
    "\n",
    "# Add markers for top 5 regions\n",
    "top_regions = map_df.nlargest(5, 'well_resourced_score')\n",
    "for idx, row in top_regions.iterrows():\n",
    "    # Get centroid coordinates\n",
    "    centroid = row['geometry'].centroid\n",
    "    popup_text = f\"\"\"\n",
    "    <b>{row['sa2_name']}</b><br>\n",
    "    Score: {row['well_resourced_score']:.2f}<br>\n",
    "    Region: {row['sa4_name_2021']}\n",
    "    \"\"\"\n",
    "    \n",
    "    folium.Marker(\n",
    "        location=[centroid.y, centroid.x],\n",
    "        popup=folium.Popup(popup_text, max_width=300),\n",
    "        icon=folium.Icon(color='green', icon='star', prefix='fa'),\n",
    "        tooltip=f\"Top Region: {row['sa2_name']}\"\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# Add title\n",
    "title_html = '''\n",
    "    <div style=\"position: fixed; \n",
    "        top: 10px; left: 50%; transform: translateX(-50%);\n",
    "        z-index:9999; font-size:18px; font-weight: bold; \n",
    "        background-color: white; padding: 10px; border-radius: 5px;\n",
    "        border:2px solid grey; text-align: center;\">\n",
    "        Well-Resourced Scores by SA2 Region - Sydney\n",
    "    </div>\n",
    "'''\n",
    "m.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "# Add layer control\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "# Add fullscreen control\n",
    "from folium.plugins import Fullscreen\n",
    "Fullscreen().add_to(m)\n",
    "\n",
    "# Add measure tool\n",
    "from folium.plugins import MeasureControl\n",
    "m.add_child(MeasureControl(position='topleft', primary_length_unit='kilometers'))\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b76da06-0ed0-4baf-96d6-4e067b914110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
